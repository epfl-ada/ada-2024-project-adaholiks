{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions used to compute the different scores\n",
    "\n",
    "They can be moved to a util.py file later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import pyarrow.feather as feather\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for utils later to get the average weights of articles from a DataFrame containing path information\n",
    "\n",
    "def calculate_avg_article_weights(df, count_cutoff=30, scaling=None):\n",
    "    \"\"\"\n",
    "    Calculate the average weights of articles from a DataFrame containing path information.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with the following columns:\n",
    "            - 'simplified_path': List of articles in the path\n",
    "            - 'simplified_path_length': Length of the simplified path\n",
    "            - 'distance': Distance associated with the path\n",
    "        scaling (str): Type of scaling to use. Options are 'minmax', 'standard', and 'robust' or None\n",
    "        count_cutoff (int): Minimum number of appearances for an article to be considered\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing:\n",
    "            - 'article': Article name\n",
    "            - 'n_appearances': Number of times the article appeared in paths\n",
    "            - 'weighted_avg': Weighted average of distances for the article\n",
    "    \"\"\"\n",
    "    # Copy and preprocess the DataFrame\n",
    "    df = df[['simplified_path', 'simplified_path_length', 'distance']].copy()\n",
    "    df['simplified_path'] = df['simplified_path'].apply(lambda l: l[1:-1])  # Remove start and end articles\n",
    "\n",
    "    # Calculate weight for each path\n",
    "    df['weight'] = df['distance'] / df['simplified_path_length']\n",
    "\n",
    "    # Initialize an empty DataFrame to store results\n",
    "    avg_article_weight_df = pd.DataFrame(columns=['article', 'n_appearances', 'weighted_avg'])\n",
    "    avg_article_weight_df.set_index('article', inplace=True)\n",
    "\n",
    "    # Iterate through each row to calculate weights\n",
    "    for _, row in df.iterrows():\n",
    "        weight = row['weight']\n",
    "        simplified_path = row['simplified_path']\n",
    "\n",
    "        for article in simplified_path:\n",
    "            if article not in avg_article_weight_df.index:\n",
    "                avg_article_weight_df.loc[article] = [0, 0]\n",
    "\n",
    "            # Update counts and weighted sums\n",
    "            avg_article_weight_df.at[article, 'n_appearances'] += 1\n",
    "            avg_article_weight_df.at[article, 'weighted_avg'] += weight\n",
    "\n",
    "    # Calculate the weighted average by dividing weighted sum by counts\n",
    "    avg_article_weight_df['weighted_avg'] = avg_article_weight_df['weighted_avg'] / avg_article_weight_df['n_appearances']\n",
    "\n",
    "    # Filter out articles that appear less than the cutoff\n",
    "    avg_article_weight_df = avg_article_weight_df[avg_article_weight_df['n_appearances'] >= count_cutoff]\n",
    "\n",
    "    # Normalize the weighted average\n",
    "    if scaling is not None:\n",
    "\n",
    "        if scaling == 'minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "        elif scaling == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "        elif scaling == 'robust':\n",
    "            scaler = RobustScaler()\n",
    "\n",
    "        avg_article_weight_df[scaling] = scaler.fit_transform(avg_article_weight_df[['weighted_avg']])\n",
    "\n",
    "\n",
    "    print(f\"Number of unique articles after weighting: {avg_article_weight_df.shape[0]}\")\n",
    "\n",
    "    return avg_article_weight_df#.reset_index()\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "# code a function that returns the ratio of the number of times an article appears in unfinished paths over the total number of times it appears\n",
    "\n",
    "def ratio_unfinished(in_df, count_cutoff=30, scaling=None):\n",
    "    \"\"\"\n",
    "    Calculate the ratio of the number of times an article appears in unfinished paths over the total number of times it appears.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with the following columns:\n",
    "            - 'simplified_path': List of articles in the path\n",
    "        count_cutoff (int): Minimum number of appearances for an article to be considered\n",
    "        scaling (str): Type of scaling to use. Options are 'minmax', 'standard', and 'robust' or None\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Series containing the ratio for each article\n",
    "    \"\"\"\n",
    "    # Copy and preprocess the DataFrame\n",
    "    df = in_df[['simplified_path', 'finished']].copy()\n",
    "    df['simplified_path'] = df['simplified_path'].apply(lambda l: l[1:-1])  # Remove start and end articles\n",
    "\n",
    "    # Initialize a dictionary to store counts\n",
    "    article_counts = {}\n",
    "    unfinished_counts = {}\n",
    "\n",
    "    # Iterate through each row to calculate counts\n",
    "    for _, row in df.iterrows():\n",
    "        simplified_path = row['simplified_path']\n",
    "        finished = row['finished']\n",
    "\n",
    "        for article in simplified_path:\n",
    "            article_counts[article] = article_counts.get(article, 0) + 1\n",
    "        \n",
    "        if not finished:\n",
    "            for article in simplified_path:\n",
    "                unfinished_counts[article] = unfinished_counts.get(article, 0) + 1\n",
    "\n",
    "    # Convert the dictionary to a Series\n",
    "    article_counts = pd.Series(article_counts)\n",
    "    unfinished_counts = pd.Series(unfinished_counts)\n",
    "\n",
    "    ratio = unfinished_counts / article_counts\n",
    "\n",
    "    ratio_df = pd.DataFrame({\n",
    "    'n_appearances': article_counts,\n",
    "    'unfinished_counts': unfinished_counts,\n",
    "    'unfinished_ratio': ratio\n",
    "    }).fillna(0)\n",
    "\n",
    "    # cut off\n",
    "    ratio_df = ratio_df[ratio_df['n_appearances'] >= count_cutoff]\n",
    "\n",
    "    # scaling\n",
    "    if scaling is not None:\n",
    "        if scaling == 'minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "        elif scaling == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "        elif scaling == 'robust':\n",
    "            scaler = RobustScaler()\n",
    "        \n",
    "        ratio_df[scaling] = -scaler.fit_transform(ratio_df[['unfinished_ratio']])\n",
    "\n",
    "    #print(f\"Number of unique articles: {len(article_counts)}\")\n",
    "    print(f\"Ratio of unfinished over finished paths: {1-df['finished'].mean()}\")\n",
    "    return ratio_df\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "# code a function that counts the number of dead ends an article has (difference between full path list content and simplified path list content)\n",
    "\n",
    "def calculate_detour_ratios(in_df, count_cutoff=1, scaling=None):\n",
    "    \"\"\"\n",
    "    Calculate the detour ratio for articles based on the full path and simplified path.\n",
    "\n",
    "    Parameters:\n",
    "        in_df (pd.DataFrame): Input DataFrame with the following columns:\n",
    "            - 'full_path': List of articles in the full path\n",
    "            - 'simplified_path': List of articles in the simplified path\n",
    "        count_cutoff (int): Minimum number of detours for an article to be considered.\n",
    "        scaling (str): Type of scaling to use. Options are 'minmax', 'standard', and 'robust' or None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the detour ratio and scaled values for each article.\n",
    "    \"\"\"\n",
    "    # Copy and preprocess the DataFrame\n",
    "    df = in_df[['full_path', 'simplified_path']].copy()\n",
    "    df['simplified_path'] = df['simplified_path'].apply(lambda l: l[1:-1])  # Remove start and end articles\n",
    "    df['full_path'] = df['full_path'].apply(lambda l: l[1:-1])  # Remove start and end articles\n",
    "\n",
    "    # Initialize dictionaries to store counts\n",
    "    detour_counts = {}\n",
    "    total_counts = {}\n",
    "\n",
    "    # Iterate through each row to calculate detour counts and total appearances\n",
    "    for _, row in df.iterrows():\n",
    "        full_path = row['full_path']\n",
    "        simplified_path = row['simplified_path']\n",
    "\n",
    "        # Count total appearances for articles in the full path\n",
    "        for article in full_path:\n",
    "            total_counts[article] = total_counts.get(article, 0) + 1\n",
    "\n",
    "        # Find detour articles by subtracting the simplified path from the full path\n",
    "        detour_articles = set(full_path) - set(simplified_path)\n",
    "        for article in detour_articles:\n",
    "            detour_counts[article] = detour_counts.get(article, 0) + 1\n",
    "\n",
    "    # Convert counts to Series\n",
    "    detour_counts = pd.Series(detour_counts)\n",
    "    total_counts = pd.Series(total_counts)\n",
    "\n",
    "    # Fill missing detour counts with 0 for articles with no detours\n",
    "    detour_counts = detour_counts.reindex(total_counts.index, fill_value=0)\n",
    "\n",
    "    # Calculate detour ratio\n",
    "    detour_ratios = detour_counts / total_counts\n",
    "\n",
    "    # Create a DataFrame with detour counts and ratios\n",
    "    detour_df = pd.DataFrame({\n",
    "        'detour_count': detour_counts,\n",
    "        'total_count': total_counts,\n",
    "        'detour_ratio': detour_ratios\n",
    "    }).loc[detour_ratios.index]\n",
    "\n",
    "    # Filter out articles with detour ratio less than the count_cutoff\n",
    "    detour_df = detour_df[detour_df['total_count'] >= count_cutoff]\n",
    "\n",
    "    if scaling is not None:\n",
    "        # normalize\n",
    "        if scaling == 'minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "        elif scaling == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "        elif scaling == 'robust':\n",
    "            scaler = RobustScaler()\n",
    "\n",
    "        detour_df[scaling] = -scaler.fit_transform(detour_df[['detour_ratio']])\n",
    "\n",
    "    print(f\"Number of unique articles after detour ratio calculation: {len(detour_df)}\")\n",
    "\n",
    "    return detour_df\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "def calc_avg_article_time(df, count_cutoff=30, scaling=None):\n",
    "    \"\"\"\n",
    "    Calculate the average speed of articles from a DataFrame containing path information.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with the following columns:\n",
    "            - 'simplified_path': List of articles in the path\n",
    "            - 'durationInSec': Duration associated with the path\n",
    "        count_cutoff (int): Minimum number of appearances for an article to be considered\n",
    "        scaling (str): Type of scaling to use. Options are 'minmax', 'standard', and 'robust' or None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing:\n",
    "            - 'article': Article name\n",
    "            - 'n_appearances': Number of times the article appeared in paths\n",
    "            - 'avg_speed': Average speed of the article\n",
    "    \"\"\"\n",
    "    # Copy and preprocess the DataFrame\n",
    "    df = df[['simplified_path', 'durationInSec']].copy()\n",
    "\n",
    "    df['simplified_path'] = df['simplified_path'].apply(lambda l: l[1:-1])  # Remove start and end articles\n",
    "\n",
    "    # Initialize an empty DataFrame to store results\n",
    "    avg_article_speed_df = pd.DataFrame(columns=['article', 'n_appearances', 'avg_speed'])\n",
    "    avg_article_speed_df.set_index('article', inplace=True)\n",
    "\n",
    "    # Iterate through each row to calculate speeds\n",
    "    for _, row in df.iterrows():\n",
    "        speed = row['durationInSec']\n",
    "        simplified_path = row['simplified_path']\n",
    "\n",
    "        for article in simplified_path:\n",
    "            if article not in avg_article_speed_df.index:\n",
    "                avg_article_speed_df.loc[article] = [0, 0]\n",
    "\n",
    "            # Update counts and sums\n",
    "            avg_article_speed_df.at[article, 'n_appearances'] += 1\n",
    "            avg_article_speed_df.at[article, 'avg_speed'] += speed\n",
    "\n",
    "    # Calculate the average speed by dividing sum by counts\n",
    "    avg_article_speed_df['avg_speed'] = avg_article_speed_df['avg_speed'] / avg_article_speed_df['n_appearances']\n",
    "\n",
    "    # Filter out articles that appear less than the cutoff\n",
    "    avg_article_speed_df = avg_article_speed_df[avg_article_speed_df['n_appearances'] >= count_cutoff]\n",
    "\n",
    "    if scaling is not None:\n",
    "        # Normalize the average speed\n",
    "        if scaling == 'minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "        elif scaling == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "        elif scaling == 'robust':\n",
    "            scaler = RobustScaler()\n",
    "        \n",
    "        avg_article_speed_df[scaling] = -scaler.fit_transform(avg_article_speed_df[['avg_speed']])\n",
    "\n",
    "    print(f\"Number of unique articles after time calc: {avg_article_speed_df.shape[0]}\")\n",
    "\n",
    "    return avg_article_speed_df#.reset_index()\n",
    "\n",
    "\n",
    "# COMMENT: could consider really computing the speed instead of the duration. speed = distance / time and then sum up and average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And a function for data filtering based on time aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_duration(df):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame based on the distance and duration bounds using the IQR method. And downsample to one IpAdress per identifier.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with the following columns:\n",
    "            - 'distance': Distance associated with the path\n",
    "            - 'durationInSec': Duration associated with the path\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame\n",
    "    \"\"\"\n",
    "    filtered_dfs = []  # List to hold filtered data for each distance group\n",
    "\n",
    "    for d in range(1, int(df['distance'].max()) + 1):\n",
    "        # Filter the DataFrame for the current distance group\n",
    "        df_d = df[df['distance'] == d]\n",
    "\n",
    "        # Compute IQR for 'durationInSec'\n",
    "        Q1 = df_d['durationInSec'].quantile(0.25)\n",
    "        Q3 = df_d['durationInSec'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Calculate upper bound based on IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Keep only rows within the upper bound\n",
    "        filtered_df_d = df_d[df_d['durationInSec'] <= upper_bound]\n",
    "\n",
    "        # Append filtered group to the list\n",
    "        filtered_dfs.append(filtered_df_d)\n",
    "\n",
    "    # Concatenate all filtered groups\n",
    "    filtered_df = pd.concat(filtered_dfs, ignore_index=True)\n",
    "    \n",
    "    # downsample data to one IpAdress per identifier\n",
    "    downsampled_df = filtered_df.groupby(['hashedIpAddress', 'identifier']).sample(n=1, random_state=42)\n",
    "\n",
    "    # Calculate the number of removed rows\n",
    "    removed = df.shape[0] - downsampled_df.shape[0]\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"In sampling a total of {removed} samples were removed, \"\n",
    "        f\"which represents {removed / df.shape[0] * 100:.3f}% of the original data.\",\n",
    "        f\"{df.shape[0]} samples remain.\")\n",
    "\n",
    "    return downsampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a composite df with all the different scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_paths = feather.read_feather('Data/dataframes/filtered_paths.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/219f9qbn3y15yynshcyrrp3c0000gn/T/ipykernel_23245/1875624518.py:43: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.75' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  avg_article_weight_df.at[article, 'weighted_avg'] += weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique articles after weighting: 820\n",
      "In sampling a total of 2471 samples were removed, which represents 5.437% of the original data. 45451 samples remain.\n",
      "Number of unique articles after time calc: 776\n",
      "Ratio of unfinished over finished paths: 0.1762317738926128\n",
      "Number of unique articles after detour ratio calculation: 871\n"
     ]
    }
   ],
   "source": [
    "finished_paths = filtered_paths[filtered_paths['finished']]\n",
    "\n",
    "# downsample data to one IpAdress per identifier\n",
    "# this way players can't just learn paths and then play them as fast as possible\n",
    "finished_paths = finished_paths.groupby(['hashedIpAddress', 'identifier']).sample(n=1, random_state=42)\n",
    "\n",
    "weight_df = calculate_avg_article_weights(finished_paths, count_cutoff=30, scaling='standard')\n",
    "time_df = calc_avg_article_time(filter_duration(finished_paths), count_cutoff=30, scaling='standard')\n",
    "unfinished_atio_df = ratio_unfinished(filtered_paths, count_cutoff=30, scaling='standard')\n",
    "detour_ratio_df = calculate_detour_ratios(finished_paths, count_cutoff=30, scaling='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_avg_scaled</th>\n",
       "      <th>weight_avg</th>\n",
       "      <th>unf_ratio_scaled</th>\n",
       "      <th>unfinished_ratio</th>\n",
       "      <th>detour_ratio_scaled</th>\n",
       "      <th>detour_ratio</th>\n",
       "      <th>avg_speed_scaled</th>\n",
       "      <th>avg_speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Philosophy</th>\n",
       "      <td>0.924846</td>\n",
       "      <td>0.643279</td>\n",
       "      <td>0.213956</td>\n",
       "      <td>0.186321</td>\n",
       "      <td>0.146164</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.245149</td>\n",
       "      <td>132.319489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathematics</th>\n",
       "      <td>0.893903</td>\n",
       "      <td>0.641757</td>\n",
       "      <td>0.896721</td>\n",
       "      <td>0.127168</td>\n",
       "      <td>1.029241</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.200423</td>\n",
       "      <td>133.090239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arithmetic</th>\n",
       "      <td>1.100646</td>\n",
       "      <td>0.651925</td>\n",
       "      <td>0.953803</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>-0.221156</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>-0.575692</td>\n",
       "      <td>146.464789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North_Africa</th>\n",
       "      <td>-0.605665</td>\n",
       "      <td>0.568005</td>\n",
       "      <td>-0.090040</td>\n",
       "      <td>0.212658</td>\n",
       "      <td>0.155223</td>\n",
       "      <td>0.055901</td>\n",
       "      <td>-0.060291</td>\n",
       "      <td>137.583039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Africa</th>\n",
       "      <td>0.907139</td>\n",
       "      <td>0.642408</td>\n",
       "      <td>0.529661</td>\n",
       "      <td>0.158969</td>\n",
       "      <td>0.973283</td>\n",
       "      <td>0.016401</td>\n",
       "      <td>0.828117</td>\n",
       "      <td>122.273364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United_States_Senate</th>\n",
       "      <td>-1.257078</td>\n",
       "      <td>0.535967</td>\n",
       "      <td>-1.073610</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>-2.311367</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>1.575148</td>\n",
       "      <td>109.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cheese</th>\n",
       "      <td>2.737321</td>\n",
       "      <td>0.732421</td>\n",
       "      <td>0.492802</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.644868</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nobel_Peace_Prize</th>\n",
       "      <td>0.919959</td>\n",
       "      <td>0.643039</td>\n",
       "      <td>0.569058</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.193466</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.610105</td>\n",
       "      <td>126.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Triassic</th>\n",
       "      <td>-0.615929</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>-0.299084</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>-1.645677</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marxism</th>\n",
       "      <td>1.915060</td>\n",
       "      <td>0.691980</td>\n",
       "      <td>0.154298</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.795185</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>1.182745</td>\n",
       "      <td>116.162162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      weight_avg_scaled  weight_avg  unf_ratio_scaled  \\\n",
       "article                                                                 \n",
       "Philosophy                     0.924846    0.643279          0.213956   \n",
       "Mathematics                    0.893903    0.641757          0.896721   \n",
       "Arithmetic                     1.100646    0.651925          0.953803   \n",
       "North_Africa                  -0.605665    0.568005         -0.090040   \n",
       "Africa                         0.907139    0.642408          0.529661   \n",
       "...                                 ...         ...               ...   \n",
       "United_States_Senate          -1.257078    0.535967         -1.073610   \n",
       "Cheese                         2.737321    0.732421          0.492802   \n",
       "Nobel_Peace_Prize              0.919959    0.643039          0.569058   \n",
       "Triassic                      -0.615929    0.567500         -0.299084   \n",
       "Marxism                        1.915060    0.691980          0.154298   \n",
       "\n",
       "                      unfinished_ratio  detour_ratio_scaled  detour_ratio  \\\n",
       "article                                                                     \n",
       "Philosophy                    0.186321             0.146164      0.056338   \n",
       "Mathematics                   0.127168             1.029241      0.013699   \n",
       "Arithmetic                    0.122222            -0.221156      0.074074   \n",
       "North_Africa                  0.212658             0.155223      0.055901   \n",
       "Africa                        0.158969             0.973283      0.016401   \n",
       "...                                ...                  ...           ...   \n",
       "United_States_Senate          0.297872            -2.311367      0.175000   \n",
       "Cheese                        0.162162             0.644868      0.032258   \n",
       "Nobel_Peace_Prize             0.155556             0.193466      0.054054   \n",
       "Triassic                      0.230769            -1.645677      0.142857   \n",
       "Marxism                       0.191489             0.795185      0.025000   \n",
       "\n",
       "                      avg_speed_scaled   avg_speed  \n",
       "article                                             \n",
       "Philosophy                    0.245149  132.319489  \n",
       "Mathematics                   0.200423  133.090239  \n",
       "Arithmetic                   -0.575692  146.464789  \n",
       "North_Africa                 -0.060291  137.583039  \n",
       "Africa                        0.828117  122.273364  \n",
       "...                                ...         ...  \n",
       "United_States_Senate          1.575148  109.400000  \n",
       "Cheese                             NaN         NaN  \n",
       "Nobel_Peace_Prize             0.610105  126.030303  \n",
       "Triassic                           NaN         NaN  \n",
       "Marxism                       1.182745  116.162162  \n",
       "\n",
       "[820 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the metrics into a composite score\n",
    "composite_df = pd.DataFrame(index=weight_df.index)\n",
    "composite_df['weight_avg_scaled'] = weight_df['standard']\n",
    "composite_df['weight_avg'] = weight_df['weighted_avg']\n",
    "\n",
    "composite_df['unf_ratio_scaled'] = unfinished_atio_df['standard']\n",
    "composite_df['unfinished_ratio'] = unfinished_atio_df['unfinished_ratio']\n",
    "\n",
    "composite_df['detour_ratio_scaled'] = detour_ratio_df['standard']\n",
    "composite_df['detour_ratio'] = detour_ratio_df['detour_ratio']\n",
    "\n",
    "composite_df['avg_speed_scaled'] = time_df['standard']\n",
    "composite_df['avg_speed'] = time_df['avg_speed']\n",
    "\n",
    "composite_df\n",
    "\n",
    "# | article | weighted_avg | avg_speed | unfinished_ratio | detour_ratio |\n",
    "# |---------|bigger better |small better|   small better  | small better |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_avg_scaled</th>\n",
       "      <th>weight_avg</th>\n",
       "      <th>unf_ratio_scaled</th>\n",
       "      <th>unfinished_ratio</th>\n",
       "      <th>detour_ratio_scaled</th>\n",
       "      <th>detour_ratio</th>\n",
       "      <th>avg_speed_scaled</th>\n",
       "      <th>avg_speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Achilles</th>\n",
       "      <td>4.811790</td>\n",
       "      <td>0.834448</td>\n",
       "      <td>0.850784</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.045308</td>\n",
       "      <td>101.297872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J._K._Rowling</th>\n",
       "      <td>4.044191</td>\n",
       "      <td>0.796696</td>\n",
       "      <td>1.006611</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.949604</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>1.277557</td>\n",
       "      <td>114.528302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mario</th>\n",
       "      <td>3.390951</td>\n",
       "      <td>0.764568</td>\n",
       "      <td>0.859010</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.277426</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.830807</td>\n",
       "      <td>150.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry_Potter</th>\n",
       "      <td>3.188972</td>\n",
       "      <td>0.754634</td>\n",
       "      <td>0.565727</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>136.457627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lead</th>\n",
       "      <td>3.156074</td>\n",
       "      <td>0.753016</td>\n",
       "      <td>0.492802</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>-3.047129</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anatomy</th>\n",
       "      <td>-2.276821</td>\n",
       "      <td>0.485813</td>\n",
       "      <td>-2.486595</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>-0.569815</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>-0.853373</td>\n",
       "      <td>151.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irrigation</th>\n",
       "      <td>-2.391556</td>\n",
       "      <td>0.480171</td>\n",
       "      <td>-1.989156</td>\n",
       "      <td>0.377193</td>\n",
       "      <td>-0.646143</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.076705</td>\n",
       "      <td>135.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gas</th>\n",
       "      <td>-2.539718</td>\n",
       "      <td>0.472884</td>\n",
       "      <td>-0.473747</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>-3.601376</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.609033</td>\n",
       "      <td>126.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atheism</th>\n",
       "      <td>-2.545097</td>\n",
       "      <td>0.472619</td>\n",
       "      <td>0.265926</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>-0.412918</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actor</th>\n",
       "      <td>-2.722738</td>\n",
       "      <td>0.463882</td>\n",
       "      <td>-3.824837</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>-1.563493</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>-1.541786</td>\n",
       "      <td>163.113208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               weight_avg_scaled  weight_avg  unf_ratio_scaled  \\\n",
       "article                                                          \n",
       "Achilles                4.811790    0.834448          0.850784   \n",
       "J._K._Rowling           4.044191    0.796696          1.006611   \n",
       "Mario                   3.390951    0.764568          0.859010   \n",
       "Harry_Potter            3.188972    0.754634          0.565727   \n",
       "Lead                    3.156074    0.753016          0.492802   \n",
       "...                          ...         ...               ...   \n",
       "Anatomy                -2.276821    0.485813         -2.486595   \n",
       "Irrigation             -2.391556    0.480171         -1.989156   \n",
       "Gas                    -2.539718    0.472884         -0.473747   \n",
       "Atheism                -2.545097    0.472619          0.265926   \n",
       "Actor                  -2.722738    0.463882         -3.824837   \n",
       "\n",
       "               unfinished_ratio  detour_ratio_scaled  detour_ratio  \\\n",
       "article                                                              \n",
       "Achilles               0.131148             1.312944      0.000000   \n",
       "J._K._Rowling          0.117647             0.949604      0.017544   \n",
       "Mario                  0.130435             0.277426      0.050000   \n",
       "Harry_Potter           0.155844             1.312944      0.000000   \n",
       "Lead                   0.162162            -3.047129      0.210526   \n",
       "...                         ...                  ...           ...   \n",
       "Anatomy                0.420290            -0.569815      0.090909   \n",
       "Irrigation             0.377193            -0.646143      0.094595   \n",
       "Gas                    0.245902            -3.601376      0.237288   \n",
       "Atheism                0.181818            -0.412918      0.083333   \n",
       "Actor                  0.536232            -1.563493      0.138889   \n",
       "\n",
       "               avg_speed_scaled   avg_speed  \n",
       "article                                      \n",
       "Achilles               2.045308  101.297872  \n",
       "J._K._Rowling          1.277557  114.528302  \n",
       "Mario                 -0.830807  150.861111  \n",
       "Harry_Potter           0.005016  136.457627  \n",
       "Lead                        NaN         NaN  \n",
       "...                         ...         ...  \n",
       "Anatomy               -0.853373  151.250000  \n",
       "Irrigation             0.076705  135.222222  \n",
       "Gas                    0.609033  126.048780  \n",
       "Atheism                     NaN         NaN  \n",
       "Actor                 -1.541786  163.113208  \n",
       "\n",
       "[820 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rank by highest wieght (remember weight for an article is the average of (distance / simplified_path_length) over all the paths it appears in)\n",
    "composite_df.sort_values(by='weight_avg', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_avg_scaled</th>\n",
       "      <th>weight_avg</th>\n",
       "      <th>unf_ratio_scaled</th>\n",
       "      <th>unfinished_ratio</th>\n",
       "      <th>detour_ratio_scaled</th>\n",
       "      <th>detour_ratio</th>\n",
       "      <th>avg_speed_scaled</th>\n",
       "      <th>avg_speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Frog</th>\n",
       "      <td>1.556368</td>\n",
       "      <td>0.674339</td>\n",
       "      <td>2.364533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644868</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australian_Green_Tree_Frog</th>\n",
       "      <td>1.008014</td>\n",
       "      <td>0.647369</td>\n",
       "      <td>2.364533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795185</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.458453</td>\n",
       "      <td>144.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>List_of_countries</th>\n",
       "      <td>0.528985</td>\n",
       "      <td>0.623810</td>\n",
       "      <td>2.096106</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741666</td>\n",
       "      <td>123.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Periodic_table</th>\n",
       "      <td>1.216158</td>\n",
       "      <td>0.657606</td>\n",
       "      <td>2.081005</td>\n",
       "      <td>0.024564</td>\n",
       "      <td>1.089883</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>0.671913</td>\n",
       "      <td>124.965187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kuwait</th>\n",
       "      <td>-0.397505</td>\n",
       "      <td>0.578243</td>\n",
       "      <td>2.043912</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.193466</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.504872</td>\n",
       "      <td>127.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction</th>\n",
       "      <td>-0.996283</td>\n",
       "      <td>0.548793</td>\n",
       "      <td>-3.030255</td>\n",
       "      <td>0.467391</td>\n",
       "      <td>-1.593772</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>-1.217438</td>\n",
       "      <td>157.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Simpsons</th>\n",
       "      <td>0.802556</td>\n",
       "      <td>0.637264</td>\n",
       "      <td>-3.148226</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>-0.988206</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sport</th>\n",
       "      <td>-0.963159</td>\n",
       "      <td>0.550422</td>\n",
       "      <td>-3.551640</td>\n",
       "      <td>0.512563</td>\n",
       "      <td>-2.288856</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>-0.649759</td>\n",
       "      <td>147.741176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico_City</th>\n",
       "      <td>-0.744954</td>\n",
       "      <td>0.561154</td>\n",
       "      <td>-3.581520</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>-0.311397</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>136.155556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actor</th>\n",
       "      <td>-2.722738</td>\n",
       "      <td>0.463882</td>\n",
       "      <td>-3.824837</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>-1.563493</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>-1.541786</td>\n",
       "      <td>163.113208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            weight_avg_scaled  weight_avg  unf_ratio_scaled  \\\n",
       "article                                                                       \n",
       "Frog                                 1.556368    0.674339          2.364533   \n",
       "Australian_Green_Tree_Frog           1.008014    0.647369          2.364533   \n",
       "List_of_countries                    0.528985    0.623810          2.096106   \n",
       "Periodic_table                       1.216158    0.657606          2.081005   \n",
       "Kuwait                              -0.397505    0.578243          2.043912   \n",
       "...                                       ...         ...               ...   \n",
       "Fiction                             -0.996283    0.548793         -3.030255   \n",
       "The_Simpsons                         0.802556    0.637264         -3.148226   \n",
       "Sport                               -0.963159    0.550422         -3.551640   \n",
       "Mexico_City                         -0.744954    0.561154         -3.581520   \n",
       "Actor                               -2.722738    0.463882         -3.824837   \n",
       "\n",
       "                            unfinished_ratio  detour_ratio_scaled  \\\n",
       "article                                                             \n",
       "Frog                                0.000000             0.644868   \n",
       "Australian_Green_Tree_Frog          0.000000             0.795185   \n",
       "List_of_countries                   0.023256             1.312944   \n",
       "Periodic_table                      0.024564             1.089883   \n",
       "Kuwait                              0.027778             0.193466   \n",
       "...                                      ...                  ...   \n",
       "Fiction                             0.467391            -1.593772   \n",
       "The_Simpsons                        0.477612            -0.988206   \n",
       "Sport                               0.512563            -2.288856   \n",
       "Mexico_City                         0.515152            -0.311397   \n",
       "Actor                               0.536232            -1.563493   \n",
       "\n",
       "                            detour_ratio  avg_speed_scaled   avg_speed  \n",
       "article                                                                 \n",
       "Frog                            0.032258               NaN         NaN  \n",
       "Australian_Green_Tree_Frog      0.025000         -0.458453  144.444444  \n",
       "List_of_countries               0.000000          0.741666  123.763158  \n",
       "Periodic_table                  0.010771          0.671913  124.965187  \n",
       "Kuwait                          0.054054          0.504872  127.843750  \n",
       "...                                  ...               ...         ...  \n",
       "Fiction                         0.140351         -1.217438  157.523810  \n",
       "The_Simpsons                    0.111111               NaN         NaN  \n",
       "Sport                           0.173913         -0.649759  147.741176  \n",
       "Mexico_City                     0.078431          0.022545  136.155556  \n",
       "Actor                           0.138889         -1.541786  163.113208  \n",
       "\n",
       "[820 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by unfinished ratio (ratio of the number of times an article appears in unfinished paths over the total number of times it appears)\n",
    "composite_df.sort_values(by='unf_ratio_scaled', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_avg_scaled</th>\n",
       "      <th>weight_avg</th>\n",
       "      <th>unf_ratio_scaled</th>\n",
       "      <th>unfinished_ratio</th>\n",
       "      <th>detour_ratio_scaled</th>\n",
       "      <th>detour_ratio</th>\n",
       "      <th>avg_speed_scaled</th>\n",
       "      <th>avg_speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detroit,_Michigan</th>\n",
       "      <td>0.848160</td>\n",
       "      <td>0.639507</td>\n",
       "      <td>0.748606</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.627169</td>\n",
       "      <td>199.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star_Wars</th>\n",
       "      <td>0.208158</td>\n",
       "      <td>0.608031</td>\n",
       "      <td>-0.185519</td>\n",
       "      <td>0.220930</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.352424</td>\n",
       "      <td>159.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star_Wars_Episode_IV__A_New_Hope</th>\n",
       "      <td>1.880626</td>\n",
       "      <td>0.690286</td>\n",
       "      <td>0.973890</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.333928</td>\n",
       "      <td>159.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History_of_the_world</th>\n",
       "      <td>-0.448221</td>\n",
       "      <td>0.575748</td>\n",
       "      <td>-1.186956</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.854531</td>\n",
       "      <td>121.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bread</th>\n",
       "      <td>-0.056651</td>\n",
       "      <td>0.595007</td>\n",
       "      <td>1.498857</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.438278</td>\n",
       "      <td>144.096774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yellowstone_National_Park</th>\n",
       "      <td>-0.989639</td>\n",
       "      <td>0.549120</td>\n",
       "      <td>-2.118855</td>\n",
       "      <td>0.388430</td>\n",
       "      <td>-3.289356</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-1.589729</td>\n",
       "      <td>163.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eukaryote</th>\n",
       "      <td>-1.550714</td>\n",
       "      <td>0.521525</td>\n",
       "      <td>-2.631404</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>-3.433178</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>-0.361369</td>\n",
       "      <td>142.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gas</th>\n",
       "      <td>-2.539718</td>\n",
       "      <td>0.472884</td>\n",
       "      <td>-0.473747</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>-3.601376</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.609033</td>\n",
       "      <td>126.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DVD</th>\n",
       "      <td>-1.089802</td>\n",
       "      <td>0.544194</td>\n",
       "      <td>-2.182449</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>-3.966165</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>-0.013911</td>\n",
       "      <td>136.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Optical_fiber</th>\n",
       "      <td>-1.738252</td>\n",
       "      <td>0.512302</td>\n",
       "      <td>-0.867322</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>-5.713781</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>-2.168262</td>\n",
       "      <td>173.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  weight_avg_scaled  weight_avg  \\\n",
       "article                                                           \n",
       "Detroit,_Michigan                          0.848160    0.639507   \n",
       "Star_Wars                                  0.208158    0.608031   \n",
       "Star_Wars_Episode_IV__A_New_Hope           1.880626    0.690286   \n",
       "History_of_the_world                      -0.448221    0.575748   \n",
       "Bread                                     -0.056651    0.595007   \n",
       "...                                             ...         ...   \n",
       "Yellowstone_National_Park                 -0.989639    0.549120   \n",
       "Eukaryote                                 -1.550714    0.521525   \n",
       "Gas                                       -2.539718    0.472884   \n",
       "DVD                                       -1.089802    0.544194   \n",
       "Optical_fiber                             -1.738252    0.512302   \n",
       "\n",
       "                                  unf_ratio_scaled  unfinished_ratio  \\\n",
       "article                                                                \n",
       "Detroit,_Michigan                         0.748606          0.140000   \n",
       "Star_Wars                                -0.185519          0.220930   \n",
       "Star_Wars_Episode_IV__A_New_Hope          0.973890          0.120482   \n",
       "History_of_the_world                     -1.186956          0.307692   \n",
       "Bread                                     1.498857          0.075000   \n",
       "...                                            ...               ...   \n",
       "Yellowstone_National_Park                -2.118855          0.388430   \n",
       "Eukaryote                                -2.631404          0.432836   \n",
       "Gas                                      -0.473747          0.245902   \n",
       "DVD                                      -2.182449          0.393939   \n",
       "Optical_fiber                            -0.867322          0.280000   \n",
       "\n",
       "                                  detour_ratio_scaled  detour_ratio  \\\n",
       "article                                                               \n",
       "Detroit,_Michigan                            1.312944      0.000000   \n",
       "Star_Wars                                    1.312944      0.000000   \n",
       "Star_Wars_Episode_IV__A_New_Hope             1.312944      0.000000   \n",
       "History_of_the_world                         1.312944      0.000000   \n",
       "Bread                                        1.312944      0.000000   \n",
       "...                                               ...           ...   \n",
       "Yellowstone_National_Park                   -3.289356      0.222222   \n",
       "Eukaryote                                   -3.433178      0.229167   \n",
       "Gas                                         -3.601376      0.237288   \n",
       "DVD                                         -3.966165      0.254902   \n",
       "Optical_fiber                               -5.713781      0.339286   \n",
       "\n",
       "                                  avg_speed_scaled   avg_speed  \n",
       "article                                                         \n",
       "Detroit,_Michigan                        -3.627169  199.050000  \n",
       "Star_Wars                                -1.352424  159.850000  \n",
       "Star_Wars_Episode_IV__A_New_Hope         -1.333928  159.531250  \n",
       "History_of_the_world                      0.854531  121.818182  \n",
       "Bread                                    -0.438278  144.096774  \n",
       "...                                            ...         ...  \n",
       "Yellowstone_National_Park                -1.589729  163.939394  \n",
       "Eukaryote                                -0.361369  142.771429  \n",
       "Gas                                       0.609033  126.048780  \n",
       "DVD                                      -0.013911  136.783784  \n",
       "Optical_fiber                            -2.168262  173.909091  \n",
       "\n",
       "[820 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by detour ratio (ratio of the number of dead ends an article has (difference between full path list content and simplified path list content))\n",
    "composite_df.sort_values(by='detour_ratio_scaled', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_avg_scaled</th>\n",
       "      <th>weight_avg</th>\n",
       "      <th>unf_ratio_scaled</th>\n",
       "      <th>unfinished_ratio</th>\n",
       "      <th>detour_ratio__scaled</th>\n",
       "      <th>detour_ratio</th>\n",
       "      <th>avg_speed_scaled</th>\n",
       "      <th>avg_speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>North_Korea</th>\n",
       "      <td>0.431010</td>\n",
       "      <td>0.618991</td>\n",
       "      <td>-0.153795</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>-0.890285</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>3.003798</td>\n",
       "      <td>84.780488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Old_English_language</th>\n",
       "      <td>0.054290</td>\n",
       "      <td>0.600463</td>\n",
       "      <td>-1.878974</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>-0.487956</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>2.821436</td>\n",
       "      <td>87.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korea</th>\n",
       "      <td>1.232629</td>\n",
       "      <td>0.658416</td>\n",
       "      <td>0.748606</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.842254</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>2.687098</td>\n",
       "      <td>90.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suez_Canal</th>\n",
       "      <td>0.080033</td>\n",
       "      <td>0.601729</td>\n",
       "      <td>0.979452</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>-1.223017</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>2.453527</td>\n",
       "      <td>94.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>President_of_the_United_States</th>\n",
       "      <td>1.664244</td>\n",
       "      <td>0.679644</td>\n",
       "      <td>1.205954</td>\n",
       "      <td>0.100376</td>\n",
       "      <td>0.936918</td>\n",
       "      <td>0.018156</td>\n",
       "      <td>2.117642</td>\n",
       "      <td>100.051360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welding</th>\n",
       "      <td>1.771787</td>\n",
       "      <td>0.684933</td>\n",
       "      <td>0.542058</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>List_of_rivers_by_length</th>\n",
       "      <td>1.915145</td>\n",
       "      <td>0.691984</td>\n",
       "      <td>1.006611</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oxford</th>\n",
       "      <td>-0.075141</td>\n",
       "      <td>0.594097</td>\n",
       "      <td>-0.456928</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>-1.957111</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cheese</th>\n",
       "      <td>2.737321</td>\n",
       "      <td>0.732421</td>\n",
       "      <td>0.492802</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.644868</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Triassic</th>\n",
       "      <td>-0.615929</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>-0.299084</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>-1.645677</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                weight_avg_scaled  weight_avg  \\\n",
       "article                                                         \n",
       "North_Korea                              0.431010    0.618991   \n",
       "Old_English_language                     0.054290    0.600463   \n",
       "Korea                                    1.232629    0.658416   \n",
       "Suez_Canal                               0.080033    0.601729   \n",
       "President_of_the_United_States           1.664244    0.679644   \n",
       "...                                           ...         ...   \n",
       "Welding                                  1.771787    0.684933   \n",
       "List_of_rivers_by_length                 1.915145    0.691984   \n",
       "Oxford                                  -0.075141    0.594097   \n",
       "Cheese                                   2.737321    0.732421   \n",
       "Triassic                                -0.615929    0.567500   \n",
       "\n",
       "                                unf_ratio_scaled  unfinished_ratio  \\\n",
       "article                                                              \n",
       "North_Korea                            -0.153795          0.218182   \n",
       "Old_English_language                   -1.878974          0.367647   \n",
       "Korea                                   0.748606          0.140000   \n",
       "Suez_Canal                              0.979452          0.120000   \n",
       "President_of_the_United_States          1.205954          0.100376   \n",
       "...                                          ...               ...   \n",
       "Welding                                 0.542058          0.157895   \n",
       "List_of_rivers_by_length                1.006611          0.117647   \n",
       "Oxford                                 -0.456928          0.244444   \n",
       "Cheese                                  0.492802          0.162162   \n",
       "Triassic                               -0.299084          0.230769   \n",
       "\n",
       "                                detour_ratio__scaled  detour_ratio  \\\n",
       "article                                                              \n",
       "North_Korea                                -0.890285      0.106383   \n",
       "Old_English_language                       -0.487956      0.086957   \n",
       "Korea                                       0.842254      0.022727   \n",
       "Suez_Canal                                 -1.223017      0.122449   \n",
       "President_of_the_United_States              0.936918      0.018156   \n",
       "...                                              ...           ...   \n",
       "Welding                                     1.312944      0.000000   \n",
       "List_of_rivers_by_length                    0.018547      0.062500   \n",
       "Oxford                                     -1.957111      0.157895   \n",
       "Cheese                                      0.644868      0.032258   \n",
       "Triassic                                   -1.645677      0.142857   \n",
       "\n",
       "                                avg_speed_scaled   avg_speed  \n",
       "article                                                       \n",
       "North_Korea                             3.003798   84.780488  \n",
       "Old_English_language                    2.821436   87.923077  \n",
       "Korea                                   2.687098   90.238095  \n",
       "Suez_Canal                              2.453527   94.263158  \n",
       "President_of_the_United_States          2.117642  100.051360  \n",
       "...                                          ...         ...  \n",
       "Welding                                      NaN         NaN  \n",
       "List_of_rivers_by_length                     NaN         NaN  \n",
       "Oxford                                       NaN         NaN  \n",
       "Cheese                                       NaN         NaN  \n",
       "Triassic                                     NaN         NaN  \n",
       "\n",
       "[820 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by speed (so far speed is just avg path time over all the paths an article appears in)\n",
    "composite_df.sort_values(by='avg_speed_scaled', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What now?\n",
    "\n",
    "It would be cool to **get a composite score that incorporates all the metrics but what weight do we give each individual metric...?**\n",
    "- PCA\n",
    "- Weighted average\n",
    "\n",
    "We can also seperate the game into two main objectives:\n",
    "- **Reach your target in the least possible amount of clicks**.\n",
    "    consider the following metrics\n",
    "    - weighted_avg score\n",
    "    - detour ratio \n",
    "    - maybe unfinished ratio\n",
    "- **Reach your target as fast as possible**\n",
    "    only really interested in time metric\n",
    "\n",
    "Then we can test what article attributes correlate the most with high scores. And if they are similar for clicks and time.\n",
    "\n",
    "Note that these metrics are more focused on article 'quality'. what I mean by that is that it is not the most important articles in the 'Network' (i.e. those that are the most used by players) that will have the highest scores.\n",
    "\n",
    "\n",
    "**TO DO**\n",
    "\n",
    "- code the centered sum of weights function\n",
    "\n",
    "- explain exactly each metric\n",
    "\n",
    "- compute composite scores \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_avg_scaled</th>\n",
       "      <th>unf_ratio_scaled</th>\n",
       "      <th>detour_ratio_scaled</th>\n",
       "      <th>composite_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Achilles</th>\n",
       "      <td>4.811790</td>\n",
       "      <td>0.850784</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>4.158275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J._K._Rowling</th>\n",
       "      <td>4.044191</td>\n",
       "      <td>1.006611</td>\n",
       "      <td>0.949604</td>\n",
       "      <td>3.559448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algebra</th>\n",
       "      <td>2.421177</td>\n",
       "      <td>1.664997</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>3.068307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry_Potter</th>\n",
       "      <td>3.188972</td>\n",
       "      <td>0.565727</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>2.952162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parrot</th>\n",
       "      <td>2.304506</td>\n",
       "      <td>1.180703</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>2.723494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sport</th>\n",
       "      <td>-0.963159</td>\n",
       "      <td>-3.551640</td>\n",
       "      <td>-2.288856</td>\n",
       "      <td>-3.903475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DVD</th>\n",
       "      <td>-1.089802</td>\n",
       "      <td>-2.182449</td>\n",
       "      <td>-3.966165</td>\n",
       "      <td>-4.100757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eukaryote</th>\n",
       "      <td>-1.550714</td>\n",
       "      <td>-2.631404</td>\n",
       "      <td>-3.433178</td>\n",
       "      <td>-4.369271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Optical_fiber</th>\n",
       "      <td>-1.738252</td>\n",
       "      <td>-0.867322</td>\n",
       "      <td>-5.713781</td>\n",
       "      <td>-4.701717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actor</th>\n",
       "      <td>-2.722738</td>\n",
       "      <td>-3.824837</td>\n",
       "      <td>-1.563493</td>\n",
       "      <td>-4.811791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               weight_avg_scaled  unf_ratio_scaled  detour_ratio_scaled  \\\n",
       "article                                                                   \n",
       "Achilles                4.811790          0.850784             1.312944   \n",
       "J._K._Rowling           4.044191          1.006611             0.949604   \n",
       "Algebra                 2.421177          1.664997             1.312944   \n",
       "Harry_Potter            3.188972          0.565727             1.312944   \n",
       "Parrot                  2.304506          1.180703             1.312944   \n",
       "...                          ...               ...                  ...   \n",
       "Sport                  -0.963159         -3.551640            -2.288856   \n",
       "DVD                    -1.089802         -2.182449            -3.966165   \n",
       "Eukaryote              -1.550714         -2.631404            -3.433178   \n",
       "Optical_fiber          -1.738252         -0.867322            -5.713781   \n",
       "Actor                  -2.722738         -3.824837            -1.563493   \n",
       "\n",
       "               composite_score  \n",
       "article                         \n",
       "Achilles              4.158275  \n",
       "J._K._Rowling         3.559448  \n",
       "Algebra               3.068307  \n",
       "Harry_Potter          2.952162  \n",
       "Parrot                2.723494  \n",
       "...                        ...  \n",
       "Sport                -3.903475  \n",
       "DVD                  -4.100757  \n",
       "Eukaryote            -4.369271  \n",
       "Optical_fiber        -4.701717  \n",
       "Actor                -4.811791  \n",
       "\n",
       "[820 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Ensure all metrics are such that \"bigger is better\"\n",
    "composite1_df = composite_df[['weight_avg_scaled', 'unf_ratio_scaled', 'detour_ratio_scaled']].copy()\n",
    "\n",
    "# Apply PCA to get a single composite score\n",
    "pca = PCA(n_components=1)\n",
    "composite1_df['composite_score'] = pca.fit_transform(composite1_df)\n",
    "composite1_df.sort_values(by='composite_score', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_avg_scaled</th>\n",
       "      <th>detour_ratio_scaled</th>\n",
       "      <th>composite_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Achilles</th>\n",
       "      <td>4.811790</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>4.630274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J._K._Rowling</th>\n",
       "      <td>4.044191</td>\n",
       "      <td>0.949604</td>\n",
       "      <td>3.794620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry_Potter</th>\n",
       "      <td>3.188972</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>3.310698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mario</th>\n",
       "      <td>3.390951</td>\n",
       "      <td>0.277426</td>\n",
       "      <td>2.872191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algebra</th>\n",
       "      <td>2.421177</td>\n",
       "      <td>1.312944</td>\n",
       "      <td>2.686373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Herbivore</th>\n",
       "      <td>-1.964565</td>\n",
       "      <td>-2.680531</td>\n",
       "      <td>-3.204325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DVD</th>\n",
       "      <td>-1.089802</td>\n",
       "      <td>-3.966165</td>\n",
       "      <td>-3.241349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eukaryote</th>\n",
       "      <td>-1.550714</td>\n",
       "      <td>-3.433178</td>\n",
       "      <td>-3.305899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gas</th>\n",
       "      <td>-2.539718</td>\n",
       "      <td>-3.601376</td>\n",
       "      <td>-4.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Optical_fiber</th>\n",
       "      <td>-1.738252</td>\n",
       "      <td>-5.713781</td>\n",
       "      <td>-4.785863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               weight_avg_scaled  detour_ratio_scaled  composite_score\n",
       "article                                                               \n",
       "Achilles                4.811790             1.312944         4.630274\n",
       "J._K._Rowling           4.044191             0.949604         3.794620\n",
       "Harry_Potter            3.188972             1.312944         3.310698\n",
       "Mario                   3.390951             0.277426         2.872191\n",
       "Algebra                 2.421177             1.312944         2.686373\n",
       "...                          ...                  ...              ...\n",
       "Herbivore              -1.964565            -2.680531        -3.204325\n",
       "DVD                    -1.089802            -3.966165        -3.241349\n",
       "Eukaryote              -1.550714            -3.433178        -3.305899\n",
       "Gas                    -2.539718            -3.601376        -4.208000\n",
       "Optical_fiber          -1.738252            -5.713781        -4.785863\n",
       "\n",
       "[820 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure all metrics are such that \"bigger is better\"\n",
    "composite2_df = composite_df[['weight_avg_scaled', 'detour_ratio_scaled']].copy()\n",
    "\n",
    "# Apply PCA to get a single composite score\n",
    "pca = PCA(n_components=1)\n",
    "composite2_df['composite_score'] = pca.fit_transform(composite2_df)\n",
    "composite2_df.sort_values(by='composite_score', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADAproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
