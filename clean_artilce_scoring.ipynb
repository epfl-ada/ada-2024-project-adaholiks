{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions used to compute the different scores\n",
    "\n",
    "They can be moved to a util.py file later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import pyarrow.feather as feather\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for utils later to get the average weights of articles from a DataFrame containing path information\n",
    "\n",
    "def calculate_avg_article_weights(df, count_cutoff=30, scaling='standard'):\n",
    "    \"\"\"\n",
    "    Calculate the average weights of articles from a DataFrame containing path information.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with the following columns:\n",
    "            - 'simplified_path': List of articles in the path\n",
    "            - 'simplified_path_length': Length of the simplified path\n",
    "            - 'distance': Distance associated with the path\n",
    "        scaling (str): Type of scaling to use. Options are 'minmax', 'standard', and 'robust'.\n",
    "        count_cutoff (int): Minimum number of appearances for an article to be considered\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing:\n",
    "            - 'article': Article name\n",
    "            - 'n_appearances': Number of times the article appeared in paths\n",
    "            - 'weighted_avg': Weighted average of distances for the article\n",
    "    \"\"\"\n",
    "    # Copy and preprocess the DataFrame\n",
    "    df = df[['simplified_path', 'simplified_path_length', 'distance']].copy()\n",
    "    df['simplified_path'] = df['simplified_path'].apply(lambda l: l[1:-1])  # Remove start and end articles\n",
    "\n",
    "    # Calculate weight for each path\n",
    "    df['weight'] = df['distance'] / df['simplified_path_length']\n",
    "\n",
    "    # Initialize an empty DataFrame to store results\n",
    "    avg_article_weight_df = pd.DataFrame(columns=['article', 'n_appearances', 'weighted_avg'])\n",
    "    avg_article_weight_df.set_index('article', inplace=True)\n",
    "\n",
    "    # Iterate through each row to calculate weights\n",
    "    for _, row in df.iterrows():\n",
    "        weight = row['weight']\n",
    "        simplified_path = row['simplified_path']\n",
    "\n",
    "        for article in simplified_path:\n",
    "            if article not in avg_article_weight_df.index:\n",
    "                avg_article_weight_df.loc[article] = [0, 0]\n",
    "\n",
    "            # Update counts and weighted sums\n",
    "            avg_article_weight_df.at[article, 'n_appearances'] += 1\n",
    "            avg_article_weight_df.at[article, 'weighted_avg'] += weight\n",
    "\n",
    "    # Calculate the weighted average by dividing weighted sum by counts\n",
    "    avg_article_weight_df['weighted_avg'] = avg_article_weight_df['weighted_avg'] / avg_article_weight_df['n_appearances']\n",
    "\n",
    "    # Filter out articles that appear less than the cutoff\n",
    "    avg_article_weight_df = avg_article_weight_df[avg_article_weight_df['n_appearances'] >= count_cutoff]\n",
    "\n",
    "    # Normalize the weighted average\n",
    "    if scaling == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaling == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaling == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "\n",
    "    avg_article_weight_df[scaling] = scaler.fit_transform(avg_article_weight_df[['weighted_avg']])\n",
    "\n",
    "\n",
    "    print(f\"Number of unique articles after weighting: {avg_article_weight_df.shape[0]}\")\n",
    "\n",
    "    return avg_article_weight_df#.reset_index()\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "# code a function that returns the ratio of the number of times an article appears in unfinished paths over the total number of times it appears\n",
    "\n",
    "def ratio_unfinished(in_df, count_cutoff=30, scaling='standard'):\n",
    "    \"\"\"\n",
    "    Calculate the ratio of the number of times an article appears in unfinished paths over the total number of times it appears.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with the following columns:\n",
    "            - 'simplified_path': List of articles in the path\n",
    "        count_cutoff (int): Minimum number of appearances for an article to be considered\n",
    "        scaling (str): Type of scaling to use. Options are 'minmax', 'standard', and 'robust'.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Series containing the ratio for each article\n",
    "    \"\"\"\n",
    "    # Copy and preprocess the DataFrame\n",
    "    df = in_df[['simplified_path', 'finished']].copy()\n",
    "    df['simplified_path'] = df['simplified_path'].apply(lambda l: l[1:-1])  # Remove start and end articles\n",
    "\n",
    "    # Initialize a dictionary to store counts\n",
    "    article_counts = {}\n",
    "    unfinished_counts = {}\n",
    "\n",
    "    # Iterate through each row to calculate counts\n",
    "    for _, row in df.iterrows():\n",
    "        simplified_path = row['simplified_path']\n",
    "        finished = row['finished']\n",
    "\n",
    "        for article in simplified_path:\n",
    "            article_counts[article] = article_counts.get(article, 0) + 1\n",
    "        \n",
    "        if not finished:\n",
    "            for article in simplified_path:\n",
    "                unfinished_counts[article] = unfinished_counts.get(article, 0) + 1\n",
    "\n",
    "    # Convert the dictionary to a Series\n",
    "    article_counts = pd.Series(article_counts)\n",
    "    unfinished_counts = pd.Series(unfinished_counts)\n",
    "\n",
    "    ratio = unfinished_counts / article_counts\n",
    "\n",
    "    ratio_df = pd.DataFrame({\n",
    "    'n_appearances': article_counts,\n",
    "    'unfinished_counts': unfinished_counts,\n",
    "    'unfinished_ratio': ratio\n",
    "    }).fillna(0)\n",
    "\n",
    "    # cut off\n",
    "    ratio_df = ratio_df[ratio_df['n_appearances'] >= count_cutoff]\n",
    "\n",
    "    # scaling\n",
    "    if scaling == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaling == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaling == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "    \n",
    "    ratio_df[scaling] = scaler.fit_transform(ratio_df[['unfinished_ratio']])\n",
    "\n",
    "    #print(f\"Number of unique articles: {len(article_counts)}\")\n",
    "    print(f\"Ratio of unfinished over finished paths: {1-df['finished'].mean()}\")\n",
    "    return ratio_df\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "    # code a function that counts the number of dead ends an article has (difference between full path list content and simplified path list content)\n",
    "\n",
    "def calculate_detour_ratios(in_df, count_cutoff=1, scaling='standard'):\n",
    "    \"\"\"\n",
    "    Calculate the detour ratio for articles based on the full path and simplified path.\n",
    "\n",
    "    Parameters:\n",
    "        in_df (pd.DataFrame): Input DataFrame with the following columns:\n",
    "            - 'full_path': List of articles in the full path\n",
    "            - 'simplified_path': List of articles in the simplified path\n",
    "        count_cutoff (int): Minimum number of detours for an article to be considered.\n",
    "        scaling (str): Type of scaling to use. Options are 'minmax', 'standard', and 'robust'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the detour ratio and scaled values for each article.\n",
    "    \"\"\"\n",
    "    # Copy and preprocess the DataFrame\n",
    "    df = in_df[['full_path', 'simplified_path']].copy()\n",
    "    df['simplified_path'] = df['simplified_path'].apply(lambda l: l[1:-1])  # Remove start and end articles\n",
    "    df['full_path'] = df['full_path'].apply(lambda l: l[1:-1])  # Remove start and end articles\n",
    "\n",
    "    # Initialize dictionaries to store counts\n",
    "    detour_counts = {}\n",
    "    total_counts = {}\n",
    "\n",
    "    # Iterate through each row to calculate detour counts and total appearances\n",
    "    for _, row in df.iterrows():\n",
    "        full_path = row['full_path']\n",
    "        simplified_path = row['simplified_path']\n",
    "\n",
    "        # Count total appearances for articles in the full path\n",
    "        for article in full_path:\n",
    "            total_counts[article] = total_counts.get(article, 0) + 1\n",
    "\n",
    "        # Find detour articles by subtracting the simplified path from the full path\n",
    "        detour_articles = set(full_path) - set(simplified_path)\n",
    "        for article in detour_articles:\n",
    "            detour_counts[article] = detour_counts.get(article, 0) + 1\n",
    "\n",
    "    # Convert counts to Series\n",
    "    detour_counts = pd.Series(detour_counts)\n",
    "    total_counts = pd.Series(total_counts)\n",
    "\n",
    "    # Fill missing detour counts with 0 for articles with no detours\n",
    "    detour_counts = detour_counts.reindex(total_counts.index, fill_value=0)\n",
    "\n",
    "    # Calculate detour ratio\n",
    "    detour_ratios = detour_counts / total_counts\n",
    "\n",
    "    # Create a DataFrame with detour counts and ratios\n",
    "    detour_df = pd.DataFrame({\n",
    "        'detour_count': detour_counts,\n",
    "        'total_count': total_counts,\n",
    "        'detour_ratio': detour_ratios\n",
    "    }).loc[detour_ratios.index]\n",
    "\n",
    "    # Filter out articles with detour ratio less than the count_cutoff\n",
    "    detour_df = detour_df[detour_df['total_count'] >= count_cutoff]\n",
    "\n",
    "    # Normalize the detour ratios\n",
    "    if scaling == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaling == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaling == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "\n",
    "    detour_df[scaling] = scaler.fit_transform(detour_df[['detour_ratio']])\n",
    "\n",
    "    print(f\"Number of unique articles after detour ratio calculation: {len(detour_df)}\")\n",
    "\n",
    "    return detour_df\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "def calc_avg_article_time(df, count_cutoff=30, scaling='standard'):\n",
    "    \"\"\"\n",
    "    Calculate the average speed of articles from a DataFrame containing path information.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with the following columns:\n",
    "            - 'simplified_path': List of articles in the path\n",
    "            - 'durationInSec': Duration associated with the path\n",
    "        count_cutoff (int): Minimum number of appearances for an article to be considered\n",
    "        scaling (str): Type of scaling to use. Options are 'minmax', 'standard', and 'robust'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing:\n",
    "            - 'article': Article name\n",
    "            - 'n_appearances': Number of times the article appeared in paths\n",
    "            - 'avg_speed': Average speed of the article\n",
    "    \"\"\"\n",
    "    # Copy and preprocess the DataFrame\n",
    "    df = df[['simplified_path', 'durationInSec']].copy()\n",
    "\n",
    "    df['simplified_path'] = df['simplified_path'].apply(lambda l: l[1:-1])  # Remove start and end articles\n",
    "\n",
    "    # Initialize an empty DataFrame to store results\n",
    "    avg_article_speed_df = pd.DataFrame(columns=['article', 'n_appearances', 'avg_speed'])\n",
    "    avg_article_speed_df.set_index('article', inplace=True)\n",
    "\n",
    "    # Iterate through each row to calculate speeds\n",
    "    for _, row in df.iterrows():\n",
    "        speed = row['durationInSec']\n",
    "        simplified_path = row['simplified_path']\n",
    "\n",
    "        for article in simplified_path:\n",
    "            if article not in avg_article_speed_df.index:\n",
    "                avg_article_speed_df.loc[article] = [0, 0]\n",
    "\n",
    "            # Update counts and sums\n",
    "            avg_article_speed_df.at[article, 'n_appearances'] += 1\n",
    "            avg_article_speed_df.at[article, 'avg_speed'] += speed\n",
    "\n",
    "    # Calculate the average speed by dividing sum by counts\n",
    "    avg_article_speed_df['avg_speed'] = avg_article_speed_df['avg_speed'] / avg_article_speed_df['n_appearances']\n",
    "\n",
    "    # Filter out articles that appear less than the cutoff\n",
    "    avg_article_speed_df = avg_article_speed_df[avg_article_speed_df['n_appearances'] >= count_cutoff]\n",
    "\n",
    "    # Normalize the average speed\n",
    "    if scaling == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaling == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaling == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "    \n",
    "    avg_article_speed_df[scaling] = scaler.fit_transform(avg_article_speed_df[['avg_speed']])\n",
    "\n",
    "    print(f\"Number of unique articles after time calc: {avg_article_speed_df.shape[0]}\")\n",
    "\n",
    "    return avg_article_speed_df#.reset_index()\n",
    "\n",
    "\n",
    "# COMMENT: could consider really computing the speed instead of the duration. speed = distance / time and then sum up and average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And a function for data filtering based on time aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_duration(df):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame based on the distance and duration bounds using the IQR method. And downsample to one IpAdress per identifier.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with the following columns:\n",
    "            - 'distance': Distance associated with the path\n",
    "            - 'durationInSec': Duration associated with the path\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame\n",
    "    \"\"\"\n",
    "    filtered_dfs = []  # List to hold filtered data for each distance group\n",
    "\n",
    "    for d in range(1, int(df['distance'].max()) + 1):\n",
    "        # Filter the DataFrame for the current distance group\n",
    "        df_d = df[df['distance'] == d]\n",
    "\n",
    "        # Compute IQR for 'durationInSec'\n",
    "        Q1 = df_d['durationInSec'].quantile(0.25)\n",
    "        Q3 = df_d['durationInSec'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Calculate upper bound based on IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Keep only rows within the upper bound\n",
    "        filtered_df_d = df_d[df_d['durationInSec'] <= upper_bound]\n",
    "\n",
    "        # Append filtered group to the list\n",
    "        filtered_dfs.append(filtered_df_d)\n",
    "\n",
    "    # Concatenate all filtered groups\n",
    "    filtered_df = pd.concat(filtered_dfs, ignore_index=True)\n",
    "    \n",
    "    # downsample data to one IpAdress per identifier\n",
    "    downsampled_df = filtered_df.groupby(['hashedIpAddress', 'identifier']).sample(n=1, random_state=42)\n",
    "\n",
    "    # Calculate the number of removed rows\n",
    "    removed = df.shape[0] - downsampled_df.shape[0]\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"In sampling a total of {removed} samples were removed, \"\n",
    "        f\"which represents {removed / df.shape[0] * 100:.3f}% of the original data.\",\n",
    "        f\"{df.shape[0]} samples remain.\")\n",
    "\n",
    "    return downsampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a composite df with all the different scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_paths = feather.read_feather('Data/dataframes/filtered_paths.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/219f9qbn3y15yynshcyrrp3c0000gn/T/ipykernel_21684/2940657772.py:43: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.75' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  avg_article_weight_df.at[article, 'weighted_avg'] += weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique articles after weighting: 820\n",
      "In sampling a total of 2471 samples were removed, which represents 5.437% of the original data. 45451 samples remain.\n",
      "Number of unique articles after time calc: 776\n",
      "Ratio of unfinished over finished paths: 0.1762317738926128\n",
      "Number of unique articles after detour ratio calculation: 871\n"
     ]
    }
   ],
   "source": [
    "finished_paths = filtered_paths[filtered_paths['finished']]\n",
    "\n",
    "# downsample data to one IpAdress per identifier\n",
    "# this way players can't just learn paths and then play them as fast as possible\n",
    "finished_paths = finished_paths.groupby(['hashedIpAddress', 'identifier']).sample(n=1, random_state=42)\n",
    "\n",
    "weight_df = calculate_avg_article_weights(finished_paths, count_cutoff=30, scaling='standard')\n",
    "time_df = calc_avg_article_time(filter_duration(finished_paths), count_cutoff=30, scaling='standard')\n",
    "unfinished_atio_df = ratio_unfinished(filtered_paths, count_cutoff=30, scaling='standard')\n",
    "detour_ratio_df = calculate_detour_ratios(finished_paths, count_cutoff=30, scaling='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_avg</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>unfinished_ratio</th>\n",
       "      <th>detour_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Philosophy</th>\n",
       "      <td>0.924846</td>\n",
       "      <td>-0.245149</td>\n",
       "      <td>-0.213956</td>\n",
       "      <td>-0.146164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathematics</th>\n",
       "      <td>0.893903</td>\n",
       "      <td>-0.200423</td>\n",
       "      <td>-0.896721</td>\n",
       "      <td>-1.029241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arithmetic</th>\n",
       "      <td>1.100646</td>\n",
       "      <td>0.575692</td>\n",
       "      <td>-0.953803</td>\n",
       "      <td>0.221156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North_Africa</th>\n",
       "      <td>-0.605665</td>\n",
       "      <td>0.060291</td>\n",
       "      <td>0.090040</td>\n",
       "      <td>-0.155223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Africa</th>\n",
       "      <td>0.907139</td>\n",
       "      <td>-0.828117</td>\n",
       "      <td>-0.529661</td>\n",
       "      <td>-0.973283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United_States_Senate</th>\n",
       "      <td>-1.257078</td>\n",
       "      <td>-1.575148</td>\n",
       "      <td>1.073610</td>\n",
       "      <td>2.311367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cheese</th>\n",
       "      <td>2.737321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.492802</td>\n",
       "      <td>-0.644868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nobel_Peace_Prize</th>\n",
       "      <td>0.919959</td>\n",
       "      <td>-0.610105</td>\n",
       "      <td>-0.569058</td>\n",
       "      <td>-0.193466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Triassic</th>\n",
       "      <td>-0.615929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.299084</td>\n",
       "      <td>1.645677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marxism</th>\n",
       "      <td>1.915060</td>\n",
       "      <td>-1.182745</td>\n",
       "      <td>-0.154298</td>\n",
       "      <td>-0.795185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      weighted_avg  avg_speed  unfinished_ratio  detour_ratio\n",
       "article                                                                      \n",
       "Philosophy                0.924846  -0.245149         -0.213956     -0.146164\n",
       "Mathematics               0.893903  -0.200423         -0.896721     -1.029241\n",
       "Arithmetic                1.100646   0.575692         -0.953803      0.221156\n",
       "North_Africa             -0.605665   0.060291          0.090040     -0.155223\n",
       "Africa                    0.907139  -0.828117         -0.529661     -0.973283\n",
       "...                            ...        ...               ...           ...\n",
       "United_States_Senate     -1.257078  -1.575148          1.073610      2.311367\n",
       "Cheese                    2.737321        NaN         -0.492802     -0.644868\n",
       "Nobel_Peace_Prize         0.919959  -0.610105         -0.569058     -0.193466\n",
       "Triassic                 -0.615929        NaN          0.299084      1.645677\n",
       "Marxism                   1.915060  -1.182745         -0.154298     -0.795185\n",
       "\n",
       "[820 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the metrics into a composite score\n",
    "composite_df = pd.DataFrame(index=weight_df.index)\n",
    "composite_df['weighted_avg'] = weight_df['standard']\n",
    "composite_df['avg_speed'] = time_df['standard']\n",
    "composite_df['unfinished_ratio'] = unfinished_atio_df['standard']\n",
    "composite_df['detour_ratio'] = detour_ratio_df['standard']\n",
    "\n",
    "composite_df\n",
    "\n",
    "# | article | weighted_avg | avg_speed | unfinished_ratio | detour_ratio |\n",
    "# |---------|bigger better |small better|   small better  | small better |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_avg</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>unfinished_ratio</th>\n",
       "      <th>detour_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Achilles</th>\n",
       "      <td>4.811790</td>\n",
       "      <td>-2.045308</td>\n",
       "      <td>-0.850784</td>\n",
       "      <td>-1.312944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J._K._Rowling</th>\n",
       "      <td>4.044191</td>\n",
       "      <td>-1.277557</td>\n",
       "      <td>-1.006611</td>\n",
       "      <td>-0.949604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mario</th>\n",
       "      <td>3.390951</td>\n",
       "      <td>0.830807</td>\n",
       "      <td>-0.859010</td>\n",
       "      <td>-0.277426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry_Potter</th>\n",
       "      <td>3.188972</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>-0.565727</td>\n",
       "      <td>-1.312944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lead</th>\n",
       "      <td>3.156074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.492802</td>\n",
       "      <td>3.047129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anatomy</th>\n",
       "      <td>-2.276821</td>\n",
       "      <td>0.853373</td>\n",
       "      <td>2.486595</td>\n",
       "      <td>0.569815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irrigation</th>\n",
       "      <td>-2.391556</td>\n",
       "      <td>-0.076705</td>\n",
       "      <td>1.989156</td>\n",
       "      <td>0.646143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gas</th>\n",
       "      <td>-2.539718</td>\n",
       "      <td>-0.609033</td>\n",
       "      <td>0.473747</td>\n",
       "      <td>3.601376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atheism</th>\n",
       "      <td>-2.545097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.265926</td>\n",
       "      <td>0.412918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actor</th>\n",
       "      <td>-2.722738</td>\n",
       "      <td>1.541786</td>\n",
       "      <td>3.824837</td>\n",
       "      <td>1.563493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               weighted_avg  avg_speed  unfinished_ratio  detour_ratio\n",
       "article                                                               \n",
       "Achilles           4.811790  -2.045308         -0.850784     -1.312944\n",
       "J._K._Rowling      4.044191  -1.277557         -1.006611     -0.949604\n",
       "Mario              3.390951   0.830807         -0.859010     -0.277426\n",
       "Harry_Potter       3.188972  -0.005016         -0.565727     -1.312944\n",
       "Lead               3.156074        NaN         -0.492802      3.047129\n",
       "...                     ...        ...               ...           ...\n",
       "Anatomy           -2.276821   0.853373          2.486595      0.569815\n",
       "Irrigation        -2.391556  -0.076705          1.989156      0.646143\n",
       "Gas               -2.539718  -0.609033          0.473747      3.601376\n",
       "Atheism           -2.545097        NaN         -0.265926      0.412918\n",
       "Actor             -2.722738   1.541786          3.824837      1.563493\n",
       "\n",
       "[820 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rank by highest wieght (remember weight for an article is the average of (distance / simplified_path_length) over all the paths it appears in)\n",
    "composite_df.sort_values(by='weighted_avg', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_avg</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>unfinished_ratio</th>\n",
       "      <th>detour_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>North_Korea</th>\n",
       "      <td>0.431010</td>\n",
       "      <td>-3.003798</td>\n",
       "      <td>0.153795</td>\n",
       "      <td>0.890285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Old_English_language</th>\n",
       "      <td>0.054290</td>\n",
       "      <td>-2.821436</td>\n",
       "      <td>1.878974</td>\n",
       "      <td>0.487956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korea</th>\n",
       "      <td>1.232629</td>\n",
       "      <td>-2.687098</td>\n",
       "      <td>-0.748606</td>\n",
       "      <td>-0.842254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suez_Canal</th>\n",
       "      <td>0.080033</td>\n",
       "      <td>-2.453527</td>\n",
       "      <td>-0.979452</td>\n",
       "      <td>1.223017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>President_of_the_United_States</th>\n",
       "      <td>1.664244</td>\n",
       "      <td>-2.117642</td>\n",
       "      <td>-1.205954</td>\n",
       "      <td>-0.936918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welding</th>\n",
       "      <td>1.771787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.542058</td>\n",
       "      <td>-1.312944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>List_of_rivers_by_length</th>\n",
       "      <td>1.915145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.006611</td>\n",
       "      <td>-0.018547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oxford</th>\n",
       "      <td>-0.075141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456928</td>\n",
       "      <td>1.957111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cheese</th>\n",
       "      <td>2.737321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.492802</td>\n",
       "      <td>-0.644868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Triassic</th>\n",
       "      <td>-0.615929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.299084</td>\n",
       "      <td>1.645677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                weighted_avg  avg_speed  unfinished_ratio  \\\n",
       "article                                                                     \n",
       "North_Korea                         0.431010  -3.003798          0.153795   \n",
       "Old_English_language                0.054290  -2.821436          1.878974   \n",
       "Korea                               1.232629  -2.687098         -0.748606   \n",
       "Suez_Canal                          0.080033  -2.453527         -0.979452   \n",
       "President_of_the_United_States      1.664244  -2.117642         -1.205954   \n",
       "...                                      ...        ...               ...   \n",
       "Welding                             1.771787        NaN         -0.542058   \n",
       "List_of_rivers_by_length            1.915145        NaN         -1.006611   \n",
       "Oxford                             -0.075141        NaN          0.456928   \n",
       "Cheese                              2.737321        NaN         -0.492802   \n",
       "Triassic                           -0.615929        NaN          0.299084   \n",
       "\n",
       "                                detour_ratio  \n",
       "article                                       \n",
       "North_Korea                         0.890285  \n",
       "Old_English_language                0.487956  \n",
       "Korea                              -0.842254  \n",
       "Suez_Canal                          1.223017  \n",
       "President_of_the_United_States     -0.936918  \n",
       "...                                      ...  \n",
       "Welding                            -1.312944  \n",
       "List_of_rivers_by_length           -0.018547  \n",
       "Oxford                              1.957111  \n",
       "Cheese                             -0.644868  \n",
       "Triassic                            1.645677  \n",
       "\n",
       "[820 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by speed (so far speed is just avg path time over all the paths an article appears in)\n",
    "composite_df.sort_values(by='avg_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_avg</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>unfinished_ratio</th>\n",
       "      <th>detour_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australian_Green_Tree_Frog</th>\n",
       "      <td>1.008014</td>\n",
       "      <td>0.458453</td>\n",
       "      <td>-2.364533</td>\n",
       "      <td>-0.795185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frog</th>\n",
       "      <td>1.556368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.364533</td>\n",
       "      <td>-0.644868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>List_of_countries</th>\n",
       "      <td>0.528985</td>\n",
       "      <td>-0.741666</td>\n",
       "      <td>-2.096106</td>\n",
       "      <td>-1.312944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Periodic_table</th>\n",
       "      <td>1.216158</td>\n",
       "      <td>-0.671913</td>\n",
       "      <td>-2.081005</td>\n",
       "      <td>-1.089883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kuwait</th>\n",
       "      <td>-0.397505</td>\n",
       "      <td>-0.504872</td>\n",
       "      <td>-2.043912</td>\n",
       "      <td>-0.193466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction</th>\n",
       "      <td>-0.996283</td>\n",
       "      <td>1.217438</td>\n",
       "      <td>3.030255</td>\n",
       "      <td>1.593772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Simpsons</th>\n",
       "      <td>0.802556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.148226</td>\n",
       "      <td>0.988206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sport</th>\n",
       "      <td>-0.963159</td>\n",
       "      <td>0.649759</td>\n",
       "      <td>3.551640</td>\n",
       "      <td>2.288856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico_City</th>\n",
       "      <td>-0.744954</td>\n",
       "      <td>-0.022545</td>\n",
       "      <td>3.581520</td>\n",
       "      <td>0.311397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actor</th>\n",
       "      <td>-2.722738</td>\n",
       "      <td>1.541786</td>\n",
       "      <td>3.824837</td>\n",
       "      <td>1.563493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            weighted_avg  avg_speed  unfinished_ratio  \\\n",
       "article                                                                 \n",
       "Australian_Green_Tree_Frog      1.008014   0.458453         -2.364533   \n",
       "Frog                            1.556368        NaN         -2.364533   \n",
       "List_of_countries               0.528985  -0.741666         -2.096106   \n",
       "Periodic_table                  1.216158  -0.671913         -2.081005   \n",
       "Kuwait                         -0.397505  -0.504872         -2.043912   \n",
       "...                                  ...        ...               ...   \n",
       "Fiction                        -0.996283   1.217438          3.030255   \n",
       "The_Simpsons                    0.802556        NaN          3.148226   \n",
       "Sport                          -0.963159   0.649759          3.551640   \n",
       "Mexico_City                    -0.744954  -0.022545          3.581520   \n",
       "Actor                          -2.722738   1.541786          3.824837   \n",
       "\n",
       "                            detour_ratio  \n",
       "article                                   \n",
       "Australian_Green_Tree_Frog     -0.795185  \n",
       "Frog                           -0.644868  \n",
       "List_of_countries              -1.312944  \n",
       "Periodic_table                 -1.089883  \n",
       "Kuwait                         -0.193466  \n",
       "...                                  ...  \n",
       "Fiction                         1.593772  \n",
       "The_Simpsons                    0.988206  \n",
       "Sport                           2.288856  \n",
       "Mexico_City                     0.311397  \n",
       "Actor                           1.563493  \n",
       "\n",
       "[820 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by unfinished ratio (ratio of the number of times an article appears in unfinished paths over the total number of times it appears)\n",
    "composite_df.sort_values(by='unfinished_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_avg</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>unfinished_ratio</th>\n",
       "      <th>detour_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Welding</th>\n",
       "      <td>1.771787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.542058</td>\n",
       "      <td>-1.312944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coin</th>\n",
       "      <td>0.816901</td>\n",
       "      <td>-0.373638</td>\n",
       "      <td>-1.559253</td>\n",
       "      <td>-1.312944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>List_of_countries</th>\n",
       "      <td>0.528985</td>\n",
       "      <td>-0.741666</td>\n",
       "      <td>-2.096106</td>\n",
       "      <td>-1.312944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United_States_Congress</th>\n",
       "      <td>-0.491675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521052</td>\n",
       "      <td>-1.312944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detroit,_Michigan</th>\n",
       "      <td>0.848160</td>\n",
       "      <td>3.627169</td>\n",
       "      <td>-0.748606</td>\n",
       "      <td>-1.312944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yellowstone_National_Park</th>\n",
       "      <td>-0.989639</td>\n",
       "      <td>1.589729</td>\n",
       "      <td>2.118855</td>\n",
       "      <td>3.289356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eukaryote</th>\n",
       "      <td>-1.550714</td>\n",
       "      <td>0.361369</td>\n",
       "      <td>2.631404</td>\n",
       "      <td>3.433178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gas</th>\n",
       "      <td>-2.539718</td>\n",
       "      <td>-0.609033</td>\n",
       "      <td>0.473747</td>\n",
       "      <td>3.601376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DVD</th>\n",
       "      <td>-1.089802</td>\n",
       "      <td>0.013911</td>\n",
       "      <td>2.182449</td>\n",
       "      <td>3.966165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Optical_fiber</th>\n",
       "      <td>-1.738252</td>\n",
       "      <td>2.168262</td>\n",
       "      <td>0.867322</td>\n",
       "      <td>5.713781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           weighted_avg  avg_speed  unfinished_ratio  \\\n",
       "article                                                                \n",
       "Welding                        1.771787        NaN         -0.542058   \n",
       "Coin                           0.816901  -0.373638         -1.559253   \n",
       "List_of_countries              0.528985  -0.741666         -2.096106   \n",
       "United_States_Congress        -0.491675        NaN          0.521052   \n",
       "Detroit,_Michigan              0.848160   3.627169         -0.748606   \n",
       "...                                 ...        ...               ...   \n",
       "Yellowstone_National_Park     -0.989639   1.589729          2.118855   \n",
       "Eukaryote                     -1.550714   0.361369          2.631404   \n",
       "Gas                           -2.539718  -0.609033          0.473747   \n",
       "DVD                           -1.089802   0.013911          2.182449   \n",
       "Optical_fiber                 -1.738252   2.168262          0.867322   \n",
       "\n",
       "                           detour_ratio  \n",
       "article                                  \n",
       "Welding                       -1.312944  \n",
       "Coin                          -1.312944  \n",
       "List_of_countries             -1.312944  \n",
       "United_States_Congress        -1.312944  \n",
       "Detroit,_Michigan             -1.312944  \n",
       "...                                 ...  \n",
       "Yellowstone_National_Park      3.289356  \n",
       "Eukaryote                      3.433178  \n",
       "Gas                            3.601376  \n",
       "DVD                            3.966165  \n",
       "Optical_fiber                  5.713781  \n",
       "\n",
       "[820 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by detour ratio (ratio of the number of dead ends an article has (difference between full path list content and simplified path list content))\n",
    "composite_df.sort_values(by='detour_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What now?\n",
    "\n",
    "It would be cool to **get a composite score that incorporates all the metrics but what weight do we give each individual metric...?**\n",
    "\n",
    "We can also seperate the game into two main objectives:\n",
    "- **Reach your target in the least possible amount of clicks**.\n",
    "    consider the following metrics\n",
    "    - weighted_avg score\n",
    "    - detour ratio \n",
    "    - maybe unfinished ratio\n",
    "- **Reach your target as fast as possible**\n",
    "    only really interested in time metric\n",
    "\n",
    "Then we can test what article attributes correlate the most with high scores. And if they are similar for clicks and time.\n",
    "\n",
    "Note that these metrics are more focused on article 'quality'. what I mean by that is that it is not the most important articles in the 'Network' (i.e. those that are the most used by players) that will have the highest scores.\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADAproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
