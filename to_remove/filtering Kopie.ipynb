{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing functions\n",
    "\n",
    "of the path data, and in general the whole loading and convertion into DF should be in a .py file.\n",
    "Or maybe not?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Played Path Data Filtering (Outlier removal)\n",
    "\n",
    "**Finished Paths**\n",
    "- Fitler for path length  \n",
    "    So far, filtered using IQR method with full_path_length - distance to detect outliers  \n",
    "    Alternatively, could do filtering for each distance using the IQR method (like I do for speed)\n",
    "- Filtering for path speed\n",
    "    Group articles by distance. For each distance filter out slow games usingn the IQR method on that group.  \n",
    "    Also fitler out start-target pairs that have been played more than one time per player (IpAdress).  \n",
    "\n",
    "**Unfinished Paths**\n",
    "- Filter for path length  \n",
    "    So far, filter using the IQR method for full_path_length  \n",
    "    and lower bound = shortest path distance  \n",
    "    Need to remove timeouts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_finished_paths(finished_paths_df, full_path_col='full_path_length', distance_col='distance', multiplier=1.5):\n",
    "    \"\"\"\n",
    "    downsample paths where the same start target pair has been played a lot more often than others, \n",
    "    and those wehre it has been played multiple times by the same player (same IpAddress and identifier).\n",
    "    Then filters paths based on the full path length for each unique distance value, using the IQR method to identify and remove outliers.\n",
    "    \n",
    "    Parameters:\n",
    "    - finished_paths (pd.DataFrame): The input DataFrame containing path data.\n",
    "    - full_path_col (str): The column name for the full path length. Default is 'full_path_length'.\n",
    "    - distance_col (str): The column name for the distance. Default is 'distance'.\n",
    "    - multiplier (float): The multiplier for the IQR to determine the bounds. Default is 1.5.\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_finished_paths (pd.DataFrame): The filtered DataFrame without outliers.\n",
    "    - removed_count (int): The number of rows removed.\n",
    "    - removed_percentage (float): The percentage of rows removed.\n",
    "    \"\"\"\n",
    "    filtered_dfs = []  # List to hold filtered data for each distance group\n",
    "\n",
    "    # first remove all paths where the start target pair has been played by the same player (same IpAddress and identifier)\n",
    "    finished_paths = finished_paths_df.groupby(['hashedIpAddress', 'identifier']).sample(n=1, random_state=42)\n",
    "\n",
    "    # ------------------------------------\n",
    "\n",
    "    # Downsample the paths so that the same start-target pair is not played more than 5 times\n",
    "\n",
    "    # Set the random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Shuffle the DataFrame\n",
    "    shuffled_df = finished_paths.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Group by 'identifier' and keep at most the first 3 rows for each group\n",
    "    filtered_paths_sampled = (\n",
    "        shuffled_df.groupby('identifier')\n",
    "        .head(5)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    finished_paths = filtered_paths_sampled\n",
    "\n",
    "    # ------------------------------------\n",
    "\n",
    "    # Apply the IQR method\n",
    "\n",
    "\n",
    "    # Iterate over each unique distance\n",
    "    for distance in finished_paths[distance_col].unique():\n",
    "        # Subset the DataFrame for the current distance group\n",
    "        df_subset = finished_paths[finished_paths[distance_col] == distance]\n",
    "\n",
    "        # Compute IQR for the full path length\n",
    "        Q1 = df_subset[full_path_col].quantile(0.25)\n",
    "        Q3 = df_subset[full_path_col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Calculate lower and upper bounds based on IQR\n",
    "        lower_bound = Q1 - multiplier * IQR\n",
    "        upper_bound = Q3 + multiplier * IQR\n",
    "\n",
    "        # Filter rows within the bounds\n",
    "        filtered_df = df_subset[(df_subset[full_path_col] >= lower_bound) & (df_subset[full_path_col] <= upper_bound)]\n",
    "\n",
    "        # Append filtered data for this group to the list\n",
    "        filtered_dfs.append(filtered_df)\n",
    "\n",
    "    # Concatenate all filtered groups\n",
    "    filtered_finished_paths = pd.concat(filtered_dfs, ignore_index=True)\n",
    "\n",
    "    # Calculate the number of removed rows and the percentage\n",
    "    removed_count = finished_paths_df.shape[0] - filtered_finished_paths.shape[0]\n",
    "    removed_percentage = (removed_count / finished_paths_df.shape[0]) * 100\n",
    "\n",
    "    # Print the summary\n",
    "    print(f\"A total of {removed_count} paths were removed from the finished paths, using IQR filtering on {full_path_col}, \"\n",
    "          f\"which represents {removed_percentage:.3f}% of the original finished data.\")\n",
    "\n",
    "    return filtered_finished_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_unfinished_paths(unfinished_paths_df, full_path_col='full_path_length', simplified_path_col='simplified_path_length', distance_col='distance', multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Filters unfinished paths based on the IQR method for each distance group. \n",
    "    The lower bound is the distance itself, and the upper bound is determined using the IQR method.\n",
    "\n",
    "    Parameters:\n",
    "    - unfinished_paths (pd.DataFrame): The input DataFrame containing unfinished path data.\n",
    "    - full_path_col (str): The column name for the full path length. Default is 'full_path_length'.\n",
    "    - simplified_path_col (str): The column name for the simplified path length. Default is 'simplified_path_length'.\n",
    "    - distance_col (str): The column name for the distance. Default is 'distance'.\n",
    "    - multiplier (float): The multiplier for the IQR to determine the upper bound. Default is 1.5.\n",
    "\n",
    "    Returns:\n",
    "    - filtered_unfinished_paths (pd.DataFrame): The filtered DataFrame without outliers.\n",
    "    - removed_count (int): The number of rows removed.\n",
    "    - removed_percentage (float): The percentage of rows removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # First remove the paths that player did not actively fail (timeout)\n",
    "    unfinished_paths = unfinished_paths_df[~(unfinished_paths_df['failure_reason'] == 'timeout')]\n",
    "\n",
    "    filtered_dfs = []  # List to hold filtered data for each distance group\n",
    "\n",
    "    # Iterate over each unique distance\n",
    "    for distance_value in unfinished_paths[distance_col].unique():\n",
    "        # Subset the DataFrame for the current distance group\n",
    "        df_subset = unfinished_paths[unfinished_paths[distance_col] == distance_value]\n",
    "\n",
    "        # Compute IQR for the full path length\n",
    "        Q1 = df_subset[full_path_col].quantile(0.25)\n",
    "        Q3 = df_subset[full_path_col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Calculate the upper bound based on IQR\n",
    "        upper_bound = Q3 + multiplier * IQR\n",
    "\n",
    "        # Apply the filtering conditions\n",
    "        filtered_df = df_subset[\n",
    "            (df_subset[full_path_col] <= upper_bound) &  # Full path length <= upper bound\n",
    "            (df_subset[simplified_path_col] >= df_subset[distance_col])  # Simplified path length >= distance\n",
    "        ]\n",
    "\n",
    "        # Append filtered data for this group to the list\n",
    "        filtered_dfs.append(filtered_df)\n",
    "\n",
    "    # Concatenate all filtered groups\n",
    "    filtered_unfinished_paths = pd.concat(filtered_dfs, ignore_index=True)\n",
    "\n",
    "    # Calculate the number of removed rows and the percentage\n",
    "    removed_count = unfinished_paths_df.shape[0] - filtered_unfinished_paths.shape[0]\n",
    "    removed_percentage = (removed_count / unfinished_paths_df.shape[0]) * 100\n",
    "\n",
    "    # Print the summary\n",
    "    print(f\"A total of {removed_count} paths were removed from the unfinished paths, \"\n",
    "          f\"which represents {removed_percentage:.3f}% of the original unfinished data.\")\n",
    "\n",
    "    return filtered_unfinished_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 10786 paths were removed from the finished paths, using IQR filtering on full_path_length, which represents 21.018% of the original finished data.\n",
      "A total of 18254 paths were removed from the unfinished paths, which represents 73.383% of the original unfinished data.\n",
      "A total of 40532 finished paths and 6621 unfinished paths remain after filtering.\n"
     ]
    }
   ],
   "source": [
    "paths = feather.read_feather('Data/dataframes/paths.feather')\n",
    "\n",
    "finished_paths = paths[paths['finished'] == True]\n",
    "unfinished_paths = paths[paths['finished'] == False]\n",
    "\n",
    "filtered_finished_paths = filter_finished_paths(finished_paths)\n",
    "filtered_unfinished_paths = filter_unfinished_paths(unfinished_paths)\n",
    "\n",
    "print(\"A total of {} finished paths and {} unfinished paths remain after filtering.\".format(filtered_finished_paths.shape[0], filtered_unfinished_paths.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_paths = pd.concat([filtered_finished_paths, filtered_unfinished_paths], ignore_index=True)\n",
    "filtered_paths.value_counts('finished')\n",
    "\n",
    "filtered_paths.to_feather('Data/dataframes/filtered_paths.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADAproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
