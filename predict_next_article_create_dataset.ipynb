{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'current_article_text': 'Full text of Article A...',\n",
       " 'possible_next_articles': ['Article B', 'Article C', 'Article D'],\n",
       " 'target_article': 'Article D',\n",
       " 'final_target_article': 'Article Z'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataset  of the format\n",
    "{\n",
    "  \"current_article_text\": \"Full text of Article A...\",\n",
    "  \"possible_next_articles\": [\"Article B\", \"Article C\", \"Article D\"],\n",
    "  \"target_article\": \"Article D\",\n",
    "  \"final_target_article\": \"Article Z\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = pd.read_feather('Data/dataframes/article_dataframe.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data['linkTarget']\n",
    "\n",
    "# Ge max number of links\n",
    "med_links = article_data['linkTarget'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4604.000000\n",
       "mean       26.038662\n",
       "std        24.201491\n",
       "min         0.000000\n",
       "25%        11.000000\n",
       "50%        19.000000\n",
       "75%        33.000000\n",
       "max       294.000000\n",
       "Name: linkTarget, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the paths\n",
    "paths_df = pd.read_feather('Data/dataframes/paths.feather')\n",
    "# only include successful paths\n",
    "paths_df = paths_df[paths_df['finished']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hashedIpAddress', 'timestamp', 'durationInSec', 'path', 'rating',\n",
       "       'finished', 'failure_reason', 'start_article', 'target_article'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    path  \\\n",
      "0      14th_century;15th_century;16th_century;Pacific...   \n",
      "1      14th_century;Europe;Africa;Atlantic_slave_trad...   \n",
      "2      14th_century;Niger;Nigeria;British_Empire;Slav...   \n",
      "3         14th_century;Renaissance;Ancient_Greece;Greece   \n",
      "4      14th_century;Italy;Roman_Catholic_Church;HIV;R...   \n",
      "...                                                  ...   \n",
      "51313                   Yagan;Ancient_Egypt;Civilization   \n",
      "51314  Yagan;Folklore;Brothers_Grimm;<;19th_century;C...   \n",
      "51315  Yagan;Australia;England;France;United_States;T...   \n",
      "51316  Yarralumla,_Australian_Capital_Territory;Austr...   \n",
      "51317                            Ziad_Jarrah;Germany;Jew   \n",
      "\n",
      "                                          processed_path  \n",
      "0      14th_century;15th_century;16th_century;Pacific...  \n",
      "1      14th_century;Europe;Africa;Atlantic_slave_trad...  \n",
      "2      14th_century;Niger;Nigeria;British_Empire;Slav...  \n",
      "3         14th_century;Renaissance;Ancient_Greece;Greece  \n",
      "4      14th_century;Italy;Roman_Catholic_Church;HIV;R...  \n",
      "...                                                  ...  \n",
      "51313                   Yagan;Ancient_Egypt;Civilization  \n",
      "51314  Yagan;Folklore;Brothers_Grimm;Folklore;19th_ce...  \n",
      "51315  Yagan;Australia;England;France;United_States;T...  \n",
      "51316  Yarralumla,_Australian_Capital_Territory;Austr...  \n",
      "51317                            Ziad_Jarrah;Germany;Jew  \n",
      "\n",
      "[51318 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# Define the function again if necessary\n",
    "def replace_back_steps(path_str):\n",
    "    articles = path_str.split(';')\n",
    "    stack = []\n",
    "    processed = []\n",
    "    \n",
    "    for article in articles:\n",
    "        if article == '<':\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "                if stack:\n",
    "                    last_article = stack[-1]\n",
    "                    processed.append(last_article)\n",
    "            # Else, skip appending anything\n",
    "        else:\n",
    "            stack.append(article)\n",
    "            processed.append(article)\n",
    "    \n",
    "    return ';'.join(processed)\n",
    "\n",
    "# Function to apply in parallel\n",
    "def parallel_process(paths):\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        processed_paths = pool.map(replace_back_steps, paths)\n",
    "    return processed_paths\n",
    "\n",
    "# Apply parallel processing\n",
    "paths_df['processed_path'] = parallel_process(paths_df['path'].tolist())\n",
    "\n",
    "# Verify the result\n",
    "print(paths_df[['path', 'processed_path']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming `paths_df` and `article_data` are your existing DataFrames\n",
    "\n",
    "# Step 1: Precompute Lookup Dictionaries\n",
    "# Ensure 'linkTarget' is a list. If it's a string separated by a delimiter (e.g., ';'), split it accordingly.\n",
    "# article_data['linkTarget'] = article_data['linkTarget'].apply(lambda x: x.split(';') if isinstance(x, str) else [])\n",
    "article_text_dict = article_data.set_index('article')['plain_text'].to_dict()\n",
    "article_links_dict = article_data.set_index('article')['linkTarget'].to_dict()\n",
    "\n",
    "# Step 2: Collect Data in Lists\n",
    "dataset_list = []\n",
    "\n",
    "for idx, row in paths_df.iterrows():\n",
    "    path_str = row['processed_path']\n",
    "    final_target_article = row['target_article']\n",
    "    \n",
    "    # Split the path into individual articles\n",
    "    current_path = path_str.split(';')\n",
    "    path_length = len(current_path)\n",
    "    \n",
    "    # Iterate over each article in the current path\n",
    "    for i, article_name in enumerate(current_path):\n",
    "        # Retrieve the current article's text\n",
    "        current_article_text = article_text_dict.get(article_name, \"\")\n",
    "        \n",
    "        # Retrieve the list of possible next articles\n",
    "        possible_next_articles = article_links_dict.get(article_name, [])\n",
    "        \n",
    "        # Determine the target article\n",
    "        if i + 1 < path_length:\n",
    "            target_article = current_path[i + 1]\n",
    "        else:\n",
    "            target_article = final_target_article\n",
    "        \n",
    "\n",
    "        # Append the data point to the list\n",
    "        dataset_list.append({\n",
    "            'current_article_text': current_article_text,\n",
    "            'possible_next_articles': possible_next_articles,\n",
    "            'target_article': target_article,\n",
    "            'final_target_article': final_target_article\n",
    "        })\n",
    "\n",
    "# Step 3: Bulk DataFrame Creation\n",
    "dataset = pd.DataFrame(dataset_list)\n",
    "\n",
    "# Optional: Free up memory by deleting the list\n",
    "del dataset_list\n",
    "\n",
    "# Optional: Reset index if needed\n",
    "dataset.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_article_text</th>\n",
       "      <th>possible_next_articles</th>\n",
       "      <th>target_article</th>\n",
       "      <th>final_target_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#copyright\\n\\n14th century\\n\\n2007 Schools ...</td>\n",
       "      <td>[13th_century, 15th_century, Abacus, Aztec, Bl...</td>\n",
       "      <td>15th_century</td>\n",
       "      <td>African_slave_trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#copyright\\n\\n15th century\\n\\n2007 Schools ...</td>\n",
       "      <td>[10th_century, 11th_century, 12th_century, 13t...</td>\n",
       "      <td>16th_century</td>\n",
       "      <td>African_slave_trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#copyright\\n\\n16th century\\n\\n2007 Schools ...</td>\n",
       "      <td>[10th_century, 11th_century, 12th_century, 13t...</td>\n",
       "      <td>Pacific_Ocean</td>\n",
       "      <td>African_slave_trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#copyright\\n\\nPacific Ocean\\n\\n2007 Schools...</td>\n",
       "      <td>[16th_century, 17th_century, 18th_century, 19t...</td>\n",
       "      <td>Atlantic_Ocean</td>\n",
       "      <td>African_slave_trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#copyright\\n\\nAtlantic Ocean\\n\\n2007 School...</td>\n",
       "      <td>[Aberdeen, Abidjan, Accra, Africa, Airship, Al...</td>\n",
       "      <td>Accra</td>\n",
       "      <td>African_slave_trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346773</th>\n",
       "      <td>#copyright\\n\\nUnited States\\n\\n2007 Schools...</td>\n",
       "      <td>[Abraham_Lincoln, Advertising, Agriculture, Am...</td>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346774</th>\n",
       "      <td>#copyright\\n\\nAbraham Lincoln\\n\\n2007 Schoo...</td>\n",
       "      <td>[Aircraft_carrier, American_Civil_War, Andrew_...</td>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346775</th>\n",
       "      <td>#copyright\\n\\nZiad Jarrah\\n\\n2007 Schools W...</td>\n",
       "      <td>[Afghanistan, Aircraft, Arabic_language, Atlan...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Jew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346776</th>\n",
       "      <td>#copyright\\n\\nGermany\\n\\n2007 Schools Wikip...</td>\n",
       "      <td>[Adolf_Hitler, Afghanistan, Agnosticism, Alban...</td>\n",
       "      <td>Jew</td>\n",
       "      <td>Jew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346777</th>\n",
       "      <td>#copyright\\n\\nJew\\n\\n2007 Schools Wikipedia...</td>\n",
       "      <td>[Adolf_Hitler, Age_of_Enlightenment, Alexander...</td>\n",
       "      <td>Jew</td>\n",
       "      <td>Jew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346778 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     current_article_text  \\\n",
       "0          #copyright\\n\\n14th century\\n\\n2007 Schools ...   \n",
       "1          #copyright\\n\\n15th century\\n\\n2007 Schools ...   \n",
       "2          #copyright\\n\\n16th century\\n\\n2007 Schools ...   \n",
       "3          #copyright\\n\\nPacific Ocean\\n\\n2007 Schools...   \n",
       "4          #copyright\\n\\nAtlantic Ocean\\n\\n2007 School...   \n",
       "...                                                   ...   \n",
       "346773     #copyright\\n\\nUnited States\\n\\n2007 Schools...   \n",
       "346774     #copyright\\n\\nAbraham Lincoln\\n\\n2007 Schoo...   \n",
       "346775     #copyright\\n\\nZiad Jarrah\\n\\n2007 Schools W...   \n",
       "346776     #copyright\\n\\nGermany\\n\\n2007 Schools Wikip...   \n",
       "346777     #copyright\\n\\nJew\\n\\n2007 Schools Wikipedia...   \n",
       "\n",
       "                                   possible_next_articles   target_article  \\\n",
       "0       [13th_century, 15th_century, Abacus, Aztec, Bl...     15th_century   \n",
       "1       [10th_century, 11th_century, 12th_century, 13t...     16th_century   \n",
       "2       [10th_century, 11th_century, 12th_century, 13t...    Pacific_Ocean   \n",
       "3       [16th_century, 17th_century, 18th_century, 19t...   Atlantic_Ocean   \n",
       "4       [Aberdeen, Abidjan, Accra, Africa, Airship, Al...            Accra   \n",
       "...                                                   ...              ...   \n",
       "346773  [Abraham_Lincoln, Advertising, Agriculture, Am...  Abraham_Lincoln   \n",
       "346774  [Aircraft_carrier, American_Civil_War, Andrew_...  Abraham_Lincoln   \n",
       "346775  [Afghanistan, Aircraft, Arabic_language, Atlan...          Germany   \n",
       "346776  [Adolf_Hitler, Afghanistan, Agnosticism, Alban...              Jew   \n",
       "346777  [Adolf_Hitler, Age_of_Enlightenment, Alexander...              Jew   \n",
       "\n",
       "       final_target_article  \n",
       "0       African_slave_trade  \n",
       "1       African_slave_trade  \n",
       "2       African_slave_trade  \n",
       "3       African_slave_trade  \n",
       "4       African_slave_trade  \n",
       "...                     ...  \n",
       "346773      Abraham_Lincoln  \n",
       "346774      Abraham_Lincoln  \n",
       "346775                  Jew  \n",
       "346776                  Jew  \n",
       "346777                  Jew  \n",
       "\n",
       "[346778 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign unique IDs to articles\n",
    "\n",
    "all_articles = article_data['article'].tolist()\n",
    "\n",
    "article_to_id = {article: idx for idx, article in enumerate(sorted(all_articles))}\n",
    "id_to_article = {idx: article for article, idx in article_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_text(text, max_length=512):\n",
    "    return tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='tf'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize tqdm with pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Initialize the fast tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "def batch_preprocess_and_save_dataset(\n",
    "    dataset, \n",
    "    article_to_id, \n",
    "    tokenizer, \n",
    "    output_dir, \n",
    "    max_length=512, \n",
    "    max_possible_next=10, \n",
    "    batch_size=1000\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset in batches and save to disk incrementally.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset (pd.DataFrame): DataFrame containing the data points.\n",
    "    - article_to_id (dict): Dictionary mapping article names to IDs.\n",
    "    - tokenizer (transformers.PreTrainedTokenizerFast): Fast tokenizer instance.\n",
    "    - output_dir (str): Directory to save processed batches.\n",
    "    - max_length (int): Maximum length for tokenization.\n",
    "    - max_possible_next (int): Maximum number of possible next articles.\n",
    "    - batch_size (int): Number of samples to process in each batch.\n",
    "    \"\"\"\n",
    "    num_samples = len(dataset)\n",
    "    batch_num = 0\n",
    "\n",
    "    # Iterate over the dataset in batches with a progress bar\n",
    "    for start in tqdm(range(0, num_samples, batch_size), desc='Processing Batches'):\n",
    "        end = min(start + batch_size, num_samples)\n",
    "        batch = dataset.iloc[start:end]\n",
    "\n",
    "        # 1. Tokenize 'current_article_text'\n",
    "        texts = batch['current_article_text'].tolist()\n",
    "        encoded = tokenizer(\n",
    "            texts,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='np'  # Return as NumPy arrays\n",
    "        )\n",
    "        input_ids_batch = encoded['input_ids']\n",
    "        attention_mask_batch = encoded['attention_mask']\n",
    "\n",
    "        # 2. Map 'possible_next_articles' to IDs with padding/truncation\n",
    "        possible_next_articles = batch['possible_next_articles'].tolist()\n",
    "        possible_next_ids_batch = np.array([\n",
    "            [article_to_id.get(article, 0) for article in articles[:max_possible_next]] + [0]*(max_possible_next - len(articles)) \n",
    "            if len(articles) < max_possible_next else [article_to_id.get(article, 0) for article in articles[:max_possible_next]]\n",
    "            for articles in possible_next_articles\n",
    "        ], dtype=np.int32)\n",
    "\n",
    "        # 3. Map 'target_article' and 'final_target_article' to IDs\n",
    "        target_ids_batch = batch['target_article'].map(lambda x: article_to_id.get(x, 0)).values\n",
    "        final_target_ids_batch = batch['final_target_article'].map(lambda x: article_to_id.get(x, 0)).values\n",
    "\n",
    "        # Combine into a dictionary\n",
    "        processed_batch = {\n",
    "            'input_ids': input_ids_batch,\n",
    "            'attention_mask': attention_mask_batch,\n",
    "            'possible_next_ids': possible_next_ids_batch,\n",
    "            'target_id': np.array(target_ids_batch, dtype=np.int32),\n",
    "            'final_target_id': np.array(final_target_ids_batch, dtype=np.int32),\n",
    "        }\n",
    "\n",
    "        # Save batch to disk using pickle\n",
    "        batch_path = f\"{output_dir}/batch_{batch_num}.pkl\"\n",
    "        with open(batch_path, 'wb') as f:\n",
    "            pickle.dump(processed_batch, f)\n",
    "\n",
    "        batch_num += 1\n",
    "\n",
    "    print(f\"All batches saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 347/347 [18:40<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All batches saved to ./processed_batches\n"
     ]
    }
   ],
   "source": [
    "batch_preprocess_and_save_dataset(\n",
    "    dataset=dataset,\n",
    "    article_to_id=article_to_id,\n",
    "    tokenizer=tokenizer,\n",
    "    output_dir='./processed_batches',\n",
    "    max_length=1024,\n",
    "    max_possible_next=32,\n",
    "    batch_size=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def load_sampled_batches_to_tf_dataset(batch_dir, sample_size=5):\n",
    "    \"\"\"\n",
    "    Load a random sample of batches from disk and create a TensorFlow dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - batch_dir (str): Directory containing the saved batches.\n",
    "    - sample_size (int): Number of batch files to sample.\n",
    "\n",
    "    Returns:\n",
    "    - tf.data.Dataset: TensorFlow dataset containing sampled data.\n",
    "    \"\"\"\n",
    "    # List all batch files in the directory\n",
    "    all_files = [f for f in sorted(os.listdir(batch_dir)) if f.endswith('.pkl')]\n",
    "\n",
    "    # Sample a subset of the files\n",
    "    sampled_files = random.sample(all_files, min(sample_size, len(all_files)))\n",
    "\n",
    "    # Placeholder lists for TensorFlow dataset creation\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    possible_next_ids_list = []\n",
    "    final_target_ids_list = []\n",
    "    target_ids_list = []\n",
    "\n",
    "    # Load sampled batches\n",
    "    for filename in sampled_files:\n",
    "        with open(os.path.join(batch_dir, filename), 'rb') as f:\n",
    "            batch = pickle.load(f)\n",
    "            \n",
    "            # Append to lists\n",
    "            input_ids_list.append(batch['input_ids'])\n",
    "            attention_mask_list.append(batch['attention_mask'])\n",
    "            possible_next_ids_list.append(batch['possible_next_ids'])\n",
    "            final_target_ids_list.append(batch['final_target_id'])\n",
    "            target_ids_list.append(batch['target_id'])\n",
    "\n",
    "    # Concatenate sampled batches into NumPy arrays\n",
    "    input_ids = np.concatenate(input_ids_list, axis=0)\n",
    "    attention_mask = np.concatenate(attention_mask_list, axis=0)\n",
    "    possible_next_ids = np.concatenate(possible_next_ids_list, axis=0)\n",
    "    final_target_ids = np.concatenate(final_target_ids_list, axis=0)\n",
    "    target_ids = np.concatenate(target_ids_list, axis=0)\n",
    "\n",
    "    # Reshape final_target_ids to (batch_size, 1)\n",
    "    final_target_ids = final_target_ids.reshape(-1, 1)\n",
    "    target_ids = target_ids.reshape(-1, 1)\n",
    "\n",
    "    # Create a TensorFlow dataset\n",
    "    tf_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "        'input_ids': tf.constant(input_ids, dtype=tf.int32),\n",
    "        'attention_mask': tf.constant(attention_mask, dtype=tf.int32),\n",
    "        'possible_next_ids': tf.constant(possible_next_ids, dtype=tf.int32),\n",
    "        'final_target_id': tf.constant(final_target_ids, dtype=tf.int32)\n",
    "    }, tf.constant(target_ids, dtype=tf.int32)))\n",
    "\n",
    "    return tf_dataset\n",
    "\n",
    "# Load a sampled dataset and apply transformations\n",
    "batch_dir = './processed_batches'\n",
    "sample_size = 20  # Adjust based on your memory capacity\n",
    "\n",
    "tf_dataset = load_sampled_batches_to_tf_dataset(batch_dir, sample_size=sample_size)\n",
    "\n",
    "# Shuffle, batch, and prefetch\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "tf_dataset = tf_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(None, 1024), dtype=tf.int32, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(None, 1024), dtype=tf.int32, name=None),\n",
       "  'possible_next_ids': TensorSpec(shape=(None, 32), dtype=tf.int32, name=None),\n",
       "  'final_target_id': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': TensorShape([32, 1024]), 'attention_mask': TensorShape([32, 1024]), 'possible_next_ids': TensorShape([32, 32]), 'final_target_id': TensorShape([32, 1])}\n",
      "Targets shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "for batch in tf_dataset.take(1):\n",
    "    inputs, targets = batch\n",
    "    print({k: v.shape for k, v in inputs.items()})\n",
    "    print(f\"Targets shape: {targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(32, 1024), dtype=int32, numpy=\n",
      "array([[  101,  1001,  9385, ...,  6719,  2965,   102],\n",
      "       [  101,  1001,  9385, ...,  1999,  1996,   102],\n",
      "       [  101,  1001,  9385, ...,  1012, 14627,   102],\n",
      "       ...,\n",
      "       [  101,  1001,  9385, ...,  2576,  3574,   102],\n",
      "       [  101,  1001,  9385, ...,  2043,  2109,   102],\n",
      "       [  101,  1001,  9385, ..., 15699, 12849,   102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(32, 1024), dtype=int32, numpy=\n",
      "array([[1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)>, 'possible_next_ids': <tf.Tensor: shape=(32, 32), dtype=int32, numpy=\n",
      "array([[ 151,  191,  385, ..., 3882, 3994, 4206],\n",
      "       [  26,  122,  234, ..., 2312, 2323, 2346],\n",
      "       [ 330,  389,  431, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  87,   96,  214, ..., 1688, 1745, 1787],\n",
      "       [ 104,  122,  138, ..., 1180, 1200, 1242],\n",
      "       [ 330,  357,  971, ..., 3209, 3210, 3217]], dtype=int32)>, 'final_target_id': <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([ 302, 3988, 1765, 2098,  313, 2649,  603, 2302, 1101, 4582, 4582,\n",
      "       1727, 2827, 1453, 2982, 3123, 1678, 4287, 2089,  705,  847,  119,\n",
      "        534, 1163, 4103, 3012, 4408,  273, 2595, 4582, 4128, 1768],\n",
      "      dtype=int32)>}\n",
      "tf.Tensor(\n",
      "[4204 3849  584 2098  907 1561 4302 3086 1101 2478 4582 1727  387 3335\n",
      " 3108 3123  902 1433 3519  140  785 1947  534 1427 3461 3216 4408  273\n",
      " 2958 3793  932 2363], shape=(32,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 21:02:46.588930: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for batch in tf_dataset.take(1):\n",
    "\n",
    "    print(batch[0])\n",
    "    print(batch[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(None, 1024), dtype=tf.int32, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(None, 1024), dtype=tf.int32, name=None),\n",
       "  'possible_next_ids': TensorSpec(shape=(None, 32), dtype=tf.int32, name=None),\n",
       "  'final_target_id': TensorSpec(shape=(None,), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(None,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the dataset\n",
    "tf_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token shape: (None, 128)\n",
      "possible_next_pooled shape: (None, 128)\n",
      "final_target_pooled shape: (None, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfoye/.pyenv/versions/FDH/lib/python3.11/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'transformer_block_2' (of type TransformerBlock) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/cfoye/.pyenv/versions/FDH/lib/python3.11/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'flatten_1' (of type Flatten) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,440</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ possible_next_id… │\n",
       "│                     │                   │            │ final_target_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ possible_next_ids   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_target_id     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_block_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">297,344</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ possible_next_id… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_bloc… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │ not_equal_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_average_p… │\n",
       "│                     │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │    \u001b[38;5;34m589,440\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ possible_next_id… │\n",
       "│                     │                   │            │ final_target_id[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ possible_next_ids   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_target_id     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_block_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m297,344\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ possible_next_id… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ transformer_bloc… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │ not_equal_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_average_p… │\n",
       "│                     │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m98,560\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m4,128\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,022,368</span> (3.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,022,368\u001b[0m (3.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,022,368</span> (3.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,022,368\u001b[0m (3.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_custom_transformer_model(vocab_size, embedding_dim, num_possible_next):\n",
    "    # Inputs\n",
    "    input_ids = tf.keras.Input(shape=(1024,), dtype=tf.int32, name='input_ids')\n",
    "    possible_next_ids = tf.keras.Input(shape=(32,), dtype=tf.int32, name='possible_next_ids')\n",
    "    final_target_id = tf.keras.Input(shape=(1,), dtype=tf.int32, name='final_target_id')\n",
    "\n",
    "    # Embedding for inputs\n",
    "    embedding_layer = tf.keras.layers.Embedding(vocab_size + 1, embedding_dim, mask_zero=True)\n",
    "    x = embedding_layer(input_ids)\n",
    "\n",
    "    # Transformer Encoder\n",
    "    transformer_block = TransformerBlock(embed_dim=embedding_dim, num_heads=4, ff_dim=128)\n",
    "    x = transformer_block(x, training=True)  # Pass `training=True`\n",
    "\n",
    "    # CLS Token\n",
    "    cls_token = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Embedding for possible next articles\n",
    "    possible_next_embedding = embedding_layer(possible_next_ids)\n",
    "    possible_next_pooled = tf.keras.layers.GlobalAveragePooling1D()(possible_next_embedding)\n",
    "\n",
    "    # Embedding for final target article\n",
    "    final_target_embedding = embedding_layer(final_target_id)\n",
    "    final_target_pooled = tf.keras.layers.Flatten()(final_target_embedding)\n",
    "\n",
    "    concatenated = tf.keras.layers.Concatenate()([cls_token, possible_next_pooled, final_target_pooled])\n",
    "    print(f\"Concatenated shape: {concatenated.shape}\")\n",
    "\n",
    "    # Feed concatenated tensor into dense layers\n",
    "    dense = tf.keras.layers.Dense(256, activation='relu')(concatenated)\n",
    "    dense = tf.keras.layers.Dropout(0.3)(dense)\n",
    "    dense = tf.keras.layers.Dense(128, activation='relu')(dense)\n",
    "    dense = tf.keras.layers.Dropout(0.3)(dense)\n",
    "\n",
    "    # Output layer\n",
    "    output = tf.keras.layers.Dense(num_possible_next, activation='softmax')(dense)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs=[input_ids, possible_next_ids, final_target_id], outputs=output)\n",
    "    print(f\"cls_token shape: {cls_token.shape}\")\n",
    "    print(f\"possible_next_pooled shape: {possible_next_pooled.shape}\")\n",
    "    print(f\"final_target_pooled shape: {final_target_pooled.shape}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build and summarize the model\n",
    "model = build_custom_transformer_model(vocab_size=len(article_to_id), embedding_dim=128, num_possible_next=32)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',  # Assumes target_ids are sparse integers\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='model_checkpoint.keras',\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='./logs',\n",
    "        update_freq='batch'\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: (32, 1024)\n",
      "attention_mask: (32, 1024)\n",
      "possible_next_ids: (32, 32)\n",
      "final_target_id: (32, 1)\n",
      "Targets: (32,)\n"
     ]
    }
   ],
   "source": [
    "for batch in tf_dataset.take(1):\n",
    "    inputs, targets = batch\n",
    "    for key, value in inputs.items():\n",
    "        print(f\"{key}: {value.shape}\")\n",
    "    print(f\"Targets: {targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfoye/.pyenv/versions/FDH/lib/python3.11/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['input_ids', 'possible_next_ids', 'final_target_id']. Received: the structure of inputs={'input_ids': '*', 'attention_mask': '*', 'possible_next_ids': '*', 'final_target_id': '*'}\n",
      "  warnings.warn(\n",
      "/home/cfoye/.pyenv/versions/FDH/lib/python3.11/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/cfoye/.pyenv/versions/FDH/lib/python3.11/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/cfoye/.pyenv/versions/FDH/lib/python3.11/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/cfoye/.pyenv/versions/FDH/lib/python3.11/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'transformer_block_1' (of type TransformerBlock) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/cfoye/.pyenv/versions/FDH/lib/python3.11/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'flatten' (of type Flatten) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Functional.call().\n\n\u001b[1mInput 0 of layer \"dense_4\" is incompatible with the layer: expected axis -1 of input shape to have value 384, but received input with shape (None, 131328)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs={'input_ids': 'tf.Tensor(shape=(None, 1024), dtype=int32)', 'attention_mask': 'tf.Tensor(shape=(None, 1024), dtype=int32)', 'possible_next_ids': 'tf.Tensor(shape=(None, 32), dtype=int32)', 'final_target_id': 'tf.Tensor(shape=(None, 1), dtype=int32)'}\n  • training=True\n  • mask={'input_ids': 'None', 'attention_mask': 'None', 'possible_next_ids': 'None', 'final_target_id': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m tf_dataset\u001b[38;5;241m.\u001b[39mtake(train_size)\n\u001b[1;32m      7\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m tf_dataset\u001b[38;5;241m.\u001b[39mskip(train_size)\n\u001b[0;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust based on your requirements\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/FDH/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/FDH/lib/python3.11/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Functional.call().\n\n\u001b[1mInput 0 of layer \"dense_4\" is incompatible with the layer: expected axis -1 of input shape to have value 384, but received input with shape (None, 131328)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs={'input_ids': 'tf.Tensor(shape=(None, 1024), dtype=int32)', 'attention_mask': 'tf.Tensor(shape=(None, 1024), dtype=int32)', 'possible_next_ids': 'tf.Tensor(shape=(None, 32), dtype=int32)', 'final_target_id': 'tf.Tensor(shape=(None, 1), dtype=int32)'}\n  • training=True\n  • mask={'input_ids': 'None', 'attention_mask': 'None', 'possible_next_ids': 'None', 'final_target_id': 'None'}"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "dataset_size = sum(1 for _ in tf_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset = tf_dataset.take(train_size)\n",
    "val_dataset = tf_dataset.skip(train_size)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,  # Adjust based on your requirements\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FDH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
